{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f169f3",
   "metadata": {},
   "source": [
    "# Lab Two: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332b1ac",
   "metadata": {},
   "source": [
    "Matt Farrow, Amber Clark, Blake Freeman, Megan Ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b631e98",
   "metadata": {},
   "source": [
    "## **2015 Flight Delays and Cancellations**\n",
    "Data Source: [Kaggle](https://www.kaggle.com/usdot/flight-delays?select=flights.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0963d",
   "metadata": {},
   "source": [
    "Our data set consists of over 5 million rows of flight information in the domestic United States for the year of 2015. In order to optimize our modeling time, we have narrowed the scope of our classification tasks to the Dallas area only (Dallas Love Field and DFW airports). \n",
    "\n",
    "The goal for this project is to build two classification models to predict the following for the DFW area:\n",
    "1. Whether or not the flight was cancelled (our binary classification model)\n",
    "2. For delayed flights, how long was the delay (in terms of groups - our multi-class classification model).\n",
    "\n",
    "Because the scope of our two classification models is different, we will create two data sets for each modelling task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556de22f",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2fae1",
   "metadata": {},
   "source": [
    "- **[10 points]** Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee56ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# from datetime import datetime\n",
    "import altair as alt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2e7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattfarrow/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3166: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Due to the way these columns are formatted, we want to keep the leading zeros during our import. Later on will convert them to a time format.\n",
    "dtype_t = {'SCHEDULED_DEPARTURE': str,\n",
    "           'DEPARTURE_TIME': str,\n",
    "           'WHEELS_OFF': str,\n",
    "           'SCHEDULED_TIME': str,\n",
    "           'WHEELS_ON': str,\n",
    "           'SCHEDULED_ARRIVAL': str,\n",
    "           'ARRIVAL_TIME': str\n",
    "          }\n",
    "\n",
    "# Read in the data directly\n",
    "airlines = pd.read_csv('../Data/airlines.csv')\n",
    "airports = pd.read_csv('../Data/airports.csv')\n",
    "flights  = pd.read_csv('../Data/flights.csv', dtype = dtype_t)\n",
    "\n",
    "# Read in the data directly from GitHub\n",
    "# airlines = pd.read_csv('https://raw.githubusercontent.com/mattfarrow1/7331-machine-learning-1/main/Data/airlines.csv')\n",
    "# airports = pd.read_csv('https://raw.githubusercontent.com/mattfarrow1/7331-machine-learning-1/main/Data/airports.csv')\n",
    "# flights  = pd.read_csv('https://media.githubusercontent.com/media/mattfarrow1/7331-machine-learning-1/main/Data/flights.csv', dtype = dtype_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ea1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in preparation for merge\n",
    "airlines.rename(columns={'IATA_CODE': 'AIRLINE_CODE'}, inplace=True)\n",
    "flights.rename(columns={'AIRLINE': 'AIRLINE_CODE'}, inplace=True)\n",
    "\n",
    "# Merge data together\n",
    "df = pd.merge(flights, airlines, on='AIRLINE_CODE', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bba8857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5819079 entries, 0 to 5819078\n",
      "Data columns (total 32 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   YEAR                 int64  \n",
      " 1   MONTH                int64  \n",
      " 2   DAY                  int64  \n",
      " 3   DAY_OF_WEEK          int64  \n",
      " 4   AIRLINE_CODE         object \n",
      " 5   FLIGHT_NUMBER        int64  \n",
      " 6   TAIL_NUMBER          object \n",
      " 7   ORIGIN_AIRPORT       object \n",
      " 8   DESTINATION_AIRPORT  object \n",
      " 9   SCHEDULED_DEPARTURE  object \n",
      " 10  DEPARTURE_TIME       object \n",
      " 11  DEPARTURE_DELAY      float64\n",
      " 12  TAXI_OUT             float64\n",
      " 13  WHEELS_OFF           object \n",
      " 14  SCHEDULED_TIME       object \n",
      " 15  ELAPSED_TIME         float64\n",
      " 16  AIR_TIME             float64\n",
      " 17  DISTANCE             int64  \n",
      " 18  WHEELS_ON            object \n",
      " 19  TAXI_IN              float64\n",
      " 20  SCHEDULED_ARRIVAL    object \n",
      " 21  ARRIVAL_TIME         object \n",
      " 22  ARRIVAL_DELAY        float64\n",
      " 23  DIVERTED             int64  \n",
      " 24  CANCELLED            int64  \n",
      " 25  CANCELLATION_REASON  object \n",
      " 26  AIR_SYSTEM_DELAY     float64\n",
      " 27  SECURITY_DELAY       float64\n",
      " 28  AIRLINE_DELAY        float64\n",
      " 29  LATE_AIRCRAFT_DELAY  float64\n",
      " 30  WEATHER_DELAY        float64\n",
      " 31  AIRLINE              object \n",
      "dtypes: float64(11), int64(8), object(13)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "# check variable types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d43f1f",
   "metadata": {},
   "source": [
    "### 1.1 Subset to DFW area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98dce4e",
   "metadata": {},
   "source": [
    "This step will reduce our data down to flights departing from Dallas area airports only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43983f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.ORIGIN_AIRPORT == 'DFW') | (df.ORIGIN_AIRPORT == 'DAL') | \n",
    "        (df.DESTINATION_AIRPORT == 'DFW') | (df.DESTINATION_AIRPORT == 'DAL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474e2b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598535, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc940ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "American Airlines Inc.          268550\n",
       "American Eagle Airlines Inc.    107226\n",
       "Southwest Airlines Co.          105345\n",
       "Atlantic Southeast Airlines      49291\n",
       "Spirit Air Lines                 17047\n",
       "Delta Air Lines Inc.             13066\n",
       "Virgin America                   10099\n",
       "Skywest Airlines Inc.             8265\n",
       "United Air Lines Inc.             7015\n",
       "US Airways Inc.                   6162\n",
       "Alaska Airlines Inc.              2698\n",
       "Frontier Airlines Inc.            2575\n",
       "JetBlue Airways                   1196\n",
       "Name: AIRLINE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check airline counts\n",
    "df['AIRLINE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9d7b1",
   "metadata": {},
   "source": [
    "American Airlines is the max class (as expected), but we do still have a decent sample size for some of the smaller airlines. We have reduced the data down from 5 million+ rows to 598,535 rows which is a much more manageable size (although still a lot of data!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0a2134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    583787\n",
       "1     14748\n",
       "Name: CANCELLED, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check cancellations\n",
    "df['CANCELLED'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca41e3",
   "metadata": {},
   "source": [
    "This is an unbalanced data set for one of our desired classification items, which is whether or not the flight is cancelled. When we are doing our test and training splits, we can either under or oversample our data, or choose a different cut-off value to optimize sensitivity and specificity in this binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca10d7",
   "metadata": {},
   "source": [
    "### 1.2 Create New Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d3219",
   "metadata": {},
   "source": [
    "The data contains several timestamp and continuous variables that add additional complexity. In order to simplify the data, we created buckets to analyze similar attributes together.\n",
    "\n",
    "We first convert SCHEDULED_DEPARTURE, DEPARTURE_TIME, ARRIVAL_TIME, and SCHEDULED_ARRIVAL into buckets based on their timestamp.\n",
    "\n",
    "    Overnight: 12:00am - 3:59am\n",
    "    Morning: 4:00am - 10:59am\n",
    "    Afternoon: 11:00am - 3:59pm\n",
    "    Evening: 4:01pm - 11:59pm\n",
    "\n",
    "[Flight] DISTANCE is also divided into buckets.\n",
    "\n",
    "    Short: 1-99 miles\n",
    "    Medium: 100-999 miles\n",
    "    Long: 1,000+ miles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb615651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE_CODE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>DEPARTURE_TIME</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>SCHEDULED_TIME</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>SCHED_DEPARTURE_TIME</th>\n",
       "      <th>ACTUAL_DEPARTURE_TIME</th>\n",
       "      <th>SCHED_ARRIVAL_TIME</th>\n",
       "      <th>ACTUAL_ARRIVAL_TIME</th>\n",
       "      <th>DISTANCE_BUCKET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1112</td>\n",
       "      <td>N3LAAA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0030</td>\n",
       "      <td>0019</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0036</td>\n",
       "      <td>195</td>\n",
       "      <td>193.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1464</td>\n",
       "      <td>0529</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0545</td>\n",
       "      <td>0532</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NK</td>\n",
       "      <td>214</td>\n",
       "      <td>N632NK</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0103</td>\n",
       "      <td>0102</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0115</td>\n",
       "      <td>147</td>\n",
       "      <td>147.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1055</td>\n",
       "      <td>0523</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0530</td>\n",
       "      <td>0529</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spirit Air Lines</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NK</td>\n",
       "      <td>972</td>\n",
       "      <td>N606NK</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0159</td>\n",
       "      <td>0158</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0209</td>\n",
       "      <td>123</td>\n",
       "      <td>125.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>868</td>\n",
       "      <td>0452</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0502</td>\n",
       "      <td>0503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spirit Air Lines</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2459</td>\n",
       "      <td>N3BDAA</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1057</td>\n",
       "      <td>N3ASAA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0515</td>\n",
       "      <td>0703</td>\n",
       "      <td>108.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0718</td>\n",
       "      <td>161</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1121</td>\n",
       "      <td>1031</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0856</td>\n",
       "      <td>1038</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE_CODE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "8   2015      1    1            4           AA           1112      N3LAAA   \n",
       "22  2015      1    1            4           NK            214      N632NK   \n",
       "41  2015      1    1            4           NK            972      N606NK   \n",
       "42  2015      1    1            4           AA           2459      N3BDAA   \n",
       "70  2015      1    1            4           AA           1057      N3ASAA   \n",
       "\n",
       "   ORIGIN_AIRPORT DESTINATION_AIRPORT SCHEDULED_DEPARTURE DEPARTURE_TIME  \\\n",
       "8             SFO                 DFW                0030           0019   \n",
       "22            LAS                 DFW                0103           0102   \n",
       "41            PHX                 DFW                0159           0158   \n",
       "42            PHX                 DFW                0200            NaN   \n",
       "70            DFW                 MIA                0515           0703   \n",
       "\n",
       "    DEPARTURE_DELAY  TAXI_OUT WHEELS_OFF SCHEDULED_TIME  ELAPSED_TIME  \\\n",
       "8             -11.0      17.0       0036            195         193.0   \n",
       "22             -1.0      13.0       0115            147         147.0   \n",
       "41             -1.0      11.0       0209            123         125.0   \n",
       "42              NaN       NaN        NaN            120           NaN   \n",
       "70            108.0      15.0       0718            161         155.0   \n",
       "\n",
       "    AIR_TIME  DISTANCE WHEELS_ON  TAXI_IN SCHEDULED_ARRIVAL ARRIVAL_TIME  \\\n",
       "8      173.0      1464      0529      3.0              0545         0532   \n",
       "22     128.0      1055      0523      6.0              0530         0529   \n",
       "41     103.0       868      0452     11.0              0502         0503   \n",
       "42       NaN       868       NaN      NaN              0500          NaN   \n",
       "70     133.0      1121      1031      7.0              0856         1038   \n",
       "\n",
       "    ARRIVAL_DELAY  DIVERTED  CANCELLED CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n",
       "8           -13.0         0          0                 NaN               NaN   \n",
       "22           -1.0         0          0                 NaN               NaN   \n",
       "41            1.0         0          0                 NaN               NaN   \n",
       "42            NaN         0          1                   B               NaN   \n",
       "70          102.0         0          0                 NaN               0.0   \n",
       "\n",
       "    SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \\\n",
       "8              NaN            NaN                  NaN            NaN   \n",
       "22             NaN            NaN                  NaN            NaN   \n",
       "41             NaN            NaN                  NaN            NaN   \n",
       "42             NaN            NaN                  NaN            NaN   \n",
       "70             0.0            0.0                  0.0          102.0   \n",
       "\n",
       "                   AIRLINE SCHED_DEPARTURE_TIME ACTUAL_DEPARTURE_TIME  \\\n",
       "8   American Airlines Inc.            overnight             overnight   \n",
       "22        Spirit Air Lines            overnight             overnight   \n",
       "41        Spirit Air Lines            overnight             overnight   \n",
       "42  American Airlines Inc.            overnight                   NaN   \n",
       "70  American Airlines Inc.              morning               morning   \n",
       "\n",
       "   SCHED_ARRIVAL_TIME ACTUAL_ARRIVAL_TIME DISTANCE_BUCKET  \n",
       "8             morning             morning            Long  \n",
       "22            morning             morning            Long  \n",
       "41            morning             morning          Medium  \n",
       "42            morning                 NaN          Medium  \n",
       "70            morning             morning            Long  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert times into buckets for morning, afternoon, and evening as most models cannot handle timestamps.\n",
    "cut_labels = ['overnight', 'morning', 'afternoon', 'evening']\n",
    "cut_bins = [0, 400, 1100, 1600, 2359]\n",
    "\n",
    "df['SCHED_DEPARTURE_TIME'] = pd.cut(df['SCHEDULED_DEPARTURE'].astype(float), \n",
    "                                    bins=cut_bins, \n",
    "                                    labels=cut_labels, \n",
    "                                    include_lowest=True)\n",
    "df['ACTUAL_DEPARTURE_TIME'] = pd.cut(df['DEPARTURE_TIME'].astype(float), \n",
    "                                     bins=cut_bins, \n",
    "                                     labels=cut_labels, \n",
    "                                     include_lowest=True)\n",
    "df['SCHED_ARRIVAL_TIME'] = pd.cut(df['SCHEDULED_ARRIVAL'].astype(float), \n",
    "                                  bins=cut_bins, \n",
    "                                  labels=cut_labels, \n",
    "                                  include_lowest=True)\n",
    "df['ACTUAL_ARRIVAL_TIME'] = pd.cut(df['ARRIVAL_TIME'].astype(float), \n",
    "                                  bins=cut_bins, \n",
    "                                  labels=cut_labels, \n",
    "                                  include_lowest=True)\n",
    "\n",
    "# Bucket Flight Distance\n",
    "distance_labels = ['Short', 'Medium', 'Long']\n",
    "distance_bins   = [1, 100, 1000, np.inf]\n",
    "df['DISTANCE_BUCKET'] = pd.cut(df['DISTANCE'],\n",
    "                               bins=distance_bins,\n",
    "                               labels=distance_labels)\n",
    "\n",
    "# Look at our data with the buckets\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9de1c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morning      215255\n",
      "evening      191908\n",
      "afternoon    188790\n",
      "overnight      2582\n",
      "Name: SCHED_DEPARTURE_TIME, dtype: int64 \n",
      "\n",
      " morning      203882\n",
      "evening      193829\n",
      "afternoon    183284\n",
      "overnight      3360\n",
      "Name: ACTUAL_DEPARTURE_TIME, dtype: int64 \n",
      "\n",
      " evening      262011\n",
      "afternoon    181603\n",
      "morning      127464\n",
      "overnight     12143\n",
      "Name: ACTUAL_ARRIVAL_TIME, dtype: int64 \n",
      "\n",
      " Medium    420466\n",
      "Long      174846\n",
      "Short       3223\n",
      "Name: DISTANCE_BUCKET, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many of each bin we have\n",
    "sched_depart = df['SCHED_DEPARTURE_TIME'].value_counts()\n",
    "actual_depart = df['ACTUAL_DEPARTURE_TIME'].value_counts()\n",
    "sched_arrival = df['SCHED_ARRIVAL_TIME'].value_counts()\n",
    "sched_arrival = df['ACTUAL_ARRIVAL_TIME'].value_counts()\n",
    "dist_bucket = df['DISTANCE_BUCKET'].value_counts()\n",
    "\n",
    "print(sched_depart, '\\n\\n', actual_depart, '\\n\\n', sched_arrival, '\\n\\n', dist_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5565c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE_CODE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>DEPARTURE_TIME</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>SCHEDULED_TIME</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>SCHED_DEPARTURE_TIME</th>\n",
       "      <th>ACTUAL_DEPARTURE_TIME</th>\n",
       "      <th>SCHED_ARRIVAL_TIME</th>\n",
       "      <th>ACTUAL_ARRIVAL_TIME</th>\n",
       "      <th>DISTANCE_BUCKET</th>\n",
       "      <th>DELAYED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1112</td>\n",
       "      <td>N3LAAA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0030</td>\n",
       "      <td>0019</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0036</td>\n",
       "      <td>195</td>\n",
       "      <td>193.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1464</td>\n",
       "      <td>0529</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0545</td>\n",
       "      <td>0532</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NK</td>\n",
       "      <td>214</td>\n",
       "      <td>N632NK</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0103</td>\n",
       "      <td>0102</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0115</td>\n",
       "      <td>147</td>\n",
       "      <td>147.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1055</td>\n",
       "      <td>0523</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0530</td>\n",
       "      <td>0529</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spirit Air Lines</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NK</td>\n",
       "      <td>972</td>\n",
       "      <td>N606NK</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0159</td>\n",
       "      <td>0158</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0209</td>\n",
       "      <td>123</td>\n",
       "      <td>125.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>868</td>\n",
       "      <td>0452</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0502</td>\n",
       "      <td>0503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spirit Air Lines</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2459</td>\n",
       "      <td>N3BDAA</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1057</td>\n",
       "      <td>N3ASAA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0515</td>\n",
       "      <td>0703</td>\n",
       "      <td>108.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0718</td>\n",
       "      <td>161</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1121</td>\n",
       "      <td>1031</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0856</td>\n",
       "      <td>1038</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE_CODE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "8   2015      1    1            4           AA           1112      N3LAAA   \n",
       "22  2015      1    1            4           NK            214      N632NK   \n",
       "41  2015      1    1            4           NK            972      N606NK   \n",
       "42  2015      1    1            4           AA           2459      N3BDAA   \n",
       "70  2015      1    1            4           AA           1057      N3ASAA   \n",
       "\n",
       "   ORIGIN_AIRPORT DESTINATION_AIRPORT SCHEDULED_DEPARTURE DEPARTURE_TIME  \\\n",
       "8             SFO                 DFW                0030           0019   \n",
       "22            LAS                 DFW                0103           0102   \n",
       "41            PHX                 DFW                0159           0158   \n",
       "42            PHX                 DFW                0200            NaN   \n",
       "70            DFW                 MIA                0515           0703   \n",
       "\n",
       "    DEPARTURE_DELAY  TAXI_OUT WHEELS_OFF SCHEDULED_TIME  ELAPSED_TIME  \\\n",
       "8             -11.0      17.0       0036            195         193.0   \n",
       "22             -1.0      13.0       0115            147         147.0   \n",
       "41             -1.0      11.0       0209            123         125.0   \n",
       "42              NaN       NaN        NaN            120           NaN   \n",
       "70            108.0      15.0       0718            161         155.0   \n",
       "\n",
       "    AIR_TIME  DISTANCE WHEELS_ON  TAXI_IN SCHEDULED_ARRIVAL ARRIVAL_TIME  \\\n",
       "8      173.0      1464      0529      3.0              0545         0532   \n",
       "22     128.0      1055      0523      6.0              0530         0529   \n",
       "41     103.0       868      0452     11.0              0502         0503   \n",
       "42       NaN       868       NaN      NaN              0500          NaN   \n",
       "70     133.0      1121      1031      7.0              0856         1038   \n",
       "\n",
       "    ARRIVAL_DELAY  DIVERTED  CANCELLED CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n",
       "8           -13.0         0          0                 NaN               NaN   \n",
       "22           -1.0         0          0                 NaN               NaN   \n",
       "41            1.0         0          0                 NaN               NaN   \n",
       "42            NaN         0          1                   B               NaN   \n",
       "70          102.0         0          0                 NaN               0.0   \n",
       "\n",
       "    SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \\\n",
       "8              NaN            NaN                  NaN            NaN   \n",
       "22             NaN            NaN                  NaN            NaN   \n",
       "41             NaN            NaN                  NaN            NaN   \n",
       "42             NaN            NaN                  NaN            NaN   \n",
       "70             0.0            0.0                  0.0          102.0   \n",
       "\n",
       "                   AIRLINE SCHED_DEPARTURE_TIME ACTUAL_DEPARTURE_TIME  \\\n",
       "8   American Airlines Inc.            overnight             overnight   \n",
       "22        Spirit Air Lines            overnight             overnight   \n",
       "41        Spirit Air Lines            overnight             overnight   \n",
       "42  American Airlines Inc.            overnight                   NaN   \n",
       "70  American Airlines Inc.              morning               morning   \n",
       "\n",
       "   SCHED_ARRIVAL_TIME ACTUAL_ARRIVAL_TIME DISTANCE_BUCKET  DELAYED  \n",
       "8             morning             morning            Long        0  \n",
       "22            morning             morning            Long        0  \n",
       "41            morning             morning          Medium        1  \n",
       "42            morning                 NaN          Medium        1  \n",
       "70            morning             morning            Long        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column where the arrival_delay > 0 means it's delayed(=1) and if <= 0 it's not delayed(=0)\n",
    "get_delay = lambda x: 0 if x <= 0 else 1\n",
    "df['DELAYED'] = df.ARRIVAL_DELAY.apply(get_delay)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0c43f",
   "metadata": {},
   "source": [
    "### 1.2 Process Dates & Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86611f9",
   "metadata": {},
   "source": [
    "First we create a date column for joining up to Dallas weather information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2067bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/54487059/pandas-how-to-create-a-single-date-column-from-columns-containing-year-month\n",
    "df['FLIGHT_DATE'] = pd.to_datetime([f'{y}-{m}-{d}' for y, m, d in zip(df.YEAR, df.MONTH, df.DAY)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8c0f1",
   "metadata": {},
   "source": [
    "Next we'll write a function to convert the numeric time strings into datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0e9a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to change the way of representation of time in the column\n",
    "def fun_format_time(hours):\n",
    "        if hours == 2400:\n",
    "            hours = 0\n",
    "        else:\n",
    "            hours = \"{0:04d}\".format(int(hours))\n",
    "            Hourmin = datetime.time(int(hours[0:2]), int(hours[2:4]))\n",
    "            return Hourmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa426fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time columns\n",
    "cols = [\"SCHEDULED_DEPARTURE\", \n",
    "        \"DEPARTURE_TIME\", \n",
    "        \"SCHEDULED_ARRIVAL\", \n",
    "        \"SCHEDULED_TIME\",\n",
    "        \"ARRIVAL_TIME\",\n",
    "        \"WHEELS_ON\",\n",
    "        \"WHEELS_OFF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8f35a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>DEPARTURE_TIME</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>SCHEDULED_TIME</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0030</td>\n",
       "      <td>0019</td>\n",
       "      <td>0545</td>\n",
       "      <td>195</td>\n",
       "      <td>0532</td>\n",
       "      <td>0529</td>\n",
       "      <td>0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0103</td>\n",
       "      <td>0102</td>\n",
       "      <td>0530</td>\n",
       "      <td>147</td>\n",
       "      <td>0529</td>\n",
       "      <td>0523</td>\n",
       "      <td>0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0159</td>\n",
       "      <td>0158</td>\n",
       "      <td>0502</td>\n",
       "      <td>123</td>\n",
       "      <td>0503</td>\n",
       "      <td>0452</td>\n",
       "      <td>0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0500</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0515</td>\n",
       "      <td>0703</td>\n",
       "      <td>0856</td>\n",
       "      <td>161</td>\n",
       "      <td>1038</td>\n",
       "      <td>1031</td>\n",
       "      <td>0718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCHEDULED_DEPARTURE DEPARTURE_TIME SCHEDULED_ARRIVAL SCHEDULED_TIME  \\\n",
       "8                 0030           0019              0545            195   \n",
       "22                0103           0102              0530            147   \n",
       "41                0159           0158              0502            123   \n",
       "42                0200            NaN              0500            120   \n",
       "70                0515           0703              0856            161   \n",
       "\n",
       "   ARRIVAL_TIME WHEELS_ON WHEELS_OFF  \n",
       "8          0532      0529       0036  \n",
       "22         0529      0523       0115  \n",
       "41         0503      0452       0209  \n",
       "42          NaN       NaN        NaN  \n",
       "70         1038      1031       0718  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the data prior to conversion\n",
    "df[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269a80b",
   "metadata": {},
   "source": [
    "We noticed that record 42 has NaN where times should be. This is an example of a cancelled flight. We'll need to have our function exclude those when it processes the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2cb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert times to float in order to correctly process them through the function\n",
    "df[cols] = df[cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4786ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run times through the new function\n",
    "# Code adapted from: https://stackoverflow.com/questions/35232705/how-to-test-for-nans-in-an-apply-function-in-pandas\n",
    "df['SCHEDULED_DEPARTURE'] = df['SCHEDULED_DEPARTURE'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['DEPARTURE_TIME']      = df['DEPARTURE_TIME'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['SCHEDULED_ARRIVAL']   = df['SCHEDULED_ARRIVAL'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['ARRIVAL_TIME']        = df['ARRIVAL_TIME'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "# df['SCHEDULED_TIME']      = df['SCHEDULED_TIME'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['WHEELS_ON']           = df['WHEELS_ON'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['WHEELS_OFF']          = df['WHEELS_OFF'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d95a2b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>DEPARTURE_TIME</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>SCHEDULED_TIME</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00:30:00</td>\n",
       "      <td>00:19:00</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>05:32:00</td>\n",
       "      <td>05:29:00</td>\n",
       "      <td>00:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>01:03:00</td>\n",
       "      <td>01:02:00</td>\n",
       "      <td>05:30:00</td>\n",
       "      <td>147.0</td>\n",
       "      <td>05:29:00</td>\n",
       "      <td>05:23:00</td>\n",
       "      <td>01:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>01:59:00</td>\n",
       "      <td>01:58:00</td>\n",
       "      <td>05:02:00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>05:03:00</td>\n",
       "      <td>04:52:00</td>\n",
       "      <td>02:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>05:15:00</td>\n",
       "      <td>07:03:00</td>\n",
       "      <td>08:56:00</td>\n",
       "      <td>161.0</td>\n",
       "      <td>10:38:00</td>\n",
       "      <td>10:31:00</td>\n",
       "      <td>07:18:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCHEDULED_DEPARTURE DEPARTURE_TIME SCHEDULED_ARRIVAL  SCHEDULED_TIME  \\\n",
       "8             00:30:00       00:19:00          05:45:00           195.0   \n",
       "22            01:03:00       01:02:00          05:30:00           147.0   \n",
       "41            01:59:00       01:58:00          05:02:00           123.0   \n",
       "42            02:00:00            NaN          05:00:00           120.0   \n",
       "70            05:15:00       07:03:00          08:56:00           161.0   \n",
       "\n",
       "   ARRIVAL_TIME WHEELS_ON WHEELS_OFF  \n",
       "8      05:32:00  05:29:00   00:36:00  \n",
       "22     05:29:00  05:23:00   01:15:00  \n",
       "41     05:03:00  04:52:00   02:09:00  \n",
       "42          NaN       NaN        NaN  \n",
       "70     10:38:00  10:31:00   07:18:00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e3c39",
   "metadata": {},
   "source": [
    "Now that we have the times correctly formatted, let's combine the `FLIGHT_DATE` feature with `SCHEDULED_DEPARTURE` and `SCHEDULED_ARRIVAL` to create a complete datetime feature for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87103346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 598535 entries, 8 to 5819038\n",
      "Data columns (total 39 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   YEAR                   598535 non-null  int64         \n",
      " 1   MONTH                  598535 non-null  int64         \n",
      " 2   DAY                    598535 non-null  int64         \n",
      " 3   DAY_OF_WEEK            598535 non-null  int64         \n",
      " 4   AIRLINE_CODE           598535 non-null  object        \n",
      " 5   FLIGHT_NUMBER          598535 non-null  int64         \n",
      " 6   TAIL_NUMBER            597521 non-null  object        \n",
      " 7   ORIGIN_AIRPORT         598535 non-null  object        \n",
      " 8   DESTINATION_AIRPORT    598535 non-null  object        \n",
      " 9   SCHEDULED_DEPARTURE    598535 non-null  object        \n",
      " 10  DEPARTURE_TIME         584355 non-null  object        \n",
      " 11  DEPARTURE_DELAY        584391 non-null  float64       \n",
      " 12  TAXI_OUT               583924 non-null  float64       \n",
      " 13  WHEELS_OFF             583857 non-null  object        \n",
      " 14  SCHEDULED_TIME         598534 non-null  float64       \n",
      " 15  ELAPSED_TIME           581688 non-null  float64       \n",
      " 16  AIR_TIME               581688 non-null  float64       \n",
      " 17  DISTANCE               598535 non-null  int64         \n",
      " 18  WHEELS_ON              583276 non-null  object        \n",
      " 19  TAXI_IN                583489 non-null  float64       \n",
      " 20  SCHEDULED_ARRIVAL      598535 non-null  object        \n",
      " 21  ARRIVAL_TIME           583221 non-null  object        \n",
      " 22  ARRIVAL_DELAY          581688 non-null  float64       \n",
      " 23  DIVERTED               598535 non-null  int64         \n",
      " 24  CANCELLED              598535 non-null  int64         \n",
      " 25  CANCELLATION_REASON    14748 non-null   object        \n",
      " 26  AIR_SYSTEM_DELAY       118536 non-null  float64       \n",
      " 27  SECURITY_DELAY         118536 non-null  float64       \n",
      " 28  AIRLINE_DELAY          118536 non-null  float64       \n",
      " 29  LATE_AIRCRAFT_DELAY    118536 non-null  float64       \n",
      " 30  WEATHER_DELAY          118536 non-null  float64       \n",
      " 31  AIRLINE                598535 non-null  object        \n",
      " 32  SCHED_DEPARTURE_TIME   598535 non-null  category      \n",
      " 33  ACTUAL_DEPARTURE_TIME  584355 non-null  category      \n",
      " 34  SCHED_ARRIVAL_TIME     598535 non-null  category      \n",
      " 35  ACTUAL_ARRIVAL_TIME    583221 non-null  category      \n",
      " 36  DISTANCE_BUCKET        598535 non-null  category      \n",
      " 37  DELAYED                598535 non-null  int64         \n",
      " 38  FLIGHT_DATE            598535 non-null  datetime64[ns]\n",
      "dtypes: category(5), datetime64[ns](1), float64(12), int64(9), object(12)\n",
      "memory usage: 162.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef0bff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/17978092/combine-date-and-time-columns-using-python-pandas\n",
    "\n",
    "# Combine date & time for departure and arrival\n",
    "df['SCHEDULED_DEPARTURE_DT'] = pd.to_datetime(df['FLIGHT_DATE'].astype(str) + ' ' + df['SCHEDULED_DEPARTURE'].astype(str))\n",
    "df['SCHEDULED_ARRIVAL_DT']   = pd.to_datetime(df['FLIGHT_DATE'].astype(str) + ' ' + df['SCHEDULED_ARRIVAL'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39650377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE_CODE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>DEPARTURE_TIME</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>SCHEDULED_TIME</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>SCHED_DEPARTURE_TIME</th>\n",
       "      <th>ACTUAL_DEPARTURE_TIME</th>\n",
       "      <th>SCHED_ARRIVAL_TIME</th>\n",
       "      <th>ACTUAL_ARRIVAL_TIME</th>\n",
       "      <th>DISTANCE_BUCKET</th>\n",
       "      <th>DELAYED</th>\n",
       "      <th>FLIGHT_DATE</th>\n",
       "      <th>SCHEDULED_DEPARTURE_DT</th>\n",
       "      <th>SCHEDULED_ARRIVAL_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1112</td>\n",
       "      <td>N3LAAA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>DFW</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>00:19:00</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>00:36:00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1464</td>\n",
       "      <td>05:29:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>05:32:00</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-01 00:30:00</td>\n",
       "      <td>2015-01-01 05:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NK</td>\n",
       "      <td>214</td>\n",
       "      <td>N632NK</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DFW</td>\n",
       "      <td>01:03:00</td>\n",
       "      <td>01:02:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>01:15:00</td>\n",
       "      <td>147.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1055</td>\n",
       "      <td>05:23:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>05:30:00</td>\n",
       "      <td>05:29:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spirit Air Lines</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-01 01:03:00</td>\n",
       "      <td>2015-01-01 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NK</td>\n",
       "      <td>972</td>\n",
       "      <td>N606NK</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>01:59:00</td>\n",
       "      <td>01:58:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>02:09:00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>868</td>\n",
       "      <td>04:52:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>05:02:00</td>\n",
       "      <td>05:03:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spirit Air Lines</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-01 01:59:00</td>\n",
       "      <td>2015-01-01 05:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2459</td>\n",
       "      <td>N3BDAA</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1057</td>\n",
       "      <td>N3ASAA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>MIA</td>\n",
       "      <td>05:15:00</td>\n",
       "      <td>07:03:00</td>\n",
       "      <td>108.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>07:18:00</td>\n",
       "      <td>161.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1121</td>\n",
       "      <td>10:31:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>08:56:00</td>\n",
       "      <td>10:38:00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-01-01 05:15:00</td>\n",
       "      <td>2015-01-01 08:56:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE_CODE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "8   2015      1    1            4           AA           1112      N3LAAA   \n",
       "22  2015      1    1            4           NK            214      N632NK   \n",
       "41  2015      1    1            4           NK            972      N606NK   \n",
       "42  2015      1    1            4           AA           2459      N3BDAA   \n",
       "70  2015      1    1            4           AA           1057      N3ASAA   \n",
       "\n",
       "   ORIGIN_AIRPORT DESTINATION_AIRPORT SCHEDULED_DEPARTURE DEPARTURE_TIME  \\\n",
       "8             SFO                 DFW            00:30:00       00:19:00   \n",
       "22            LAS                 DFW            01:03:00       01:02:00   \n",
       "41            PHX                 DFW            01:59:00       01:58:00   \n",
       "42            PHX                 DFW            02:00:00            NaN   \n",
       "70            DFW                 MIA            05:15:00       07:03:00   \n",
       "\n",
       "    DEPARTURE_DELAY  TAXI_OUT WHEELS_OFF  SCHEDULED_TIME  ELAPSED_TIME  \\\n",
       "8             -11.0      17.0   00:36:00           195.0         193.0   \n",
       "22             -1.0      13.0   01:15:00           147.0         147.0   \n",
       "41             -1.0      11.0   02:09:00           123.0         125.0   \n",
       "42              NaN       NaN        NaN           120.0           NaN   \n",
       "70            108.0      15.0   07:18:00           161.0         155.0   \n",
       "\n",
       "    AIR_TIME  DISTANCE WHEELS_ON  TAXI_IN SCHEDULED_ARRIVAL ARRIVAL_TIME  \\\n",
       "8      173.0      1464  05:29:00      3.0          05:45:00     05:32:00   \n",
       "22     128.0      1055  05:23:00      6.0          05:30:00     05:29:00   \n",
       "41     103.0       868  04:52:00     11.0          05:02:00     05:03:00   \n",
       "42       NaN       868       NaN      NaN          05:00:00          NaN   \n",
       "70     133.0      1121  10:31:00      7.0          08:56:00     10:38:00   \n",
       "\n",
       "    ARRIVAL_DELAY  DIVERTED  CANCELLED CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n",
       "8           -13.0         0          0                 NaN               NaN   \n",
       "22           -1.0         0          0                 NaN               NaN   \n",
       "41            1.0         0          0                 NaN               NaN   \n",
       "42            NaN         0          1                   B               NaN   \n",
       "70          102.0         0          0                 NaN               0.0   \n",
       "\n",
       "    SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \\\n",
       "8              NaN            NaN                  NaN            NaN   \n",
       "22             NaN            NaN                  NaN            NaN   \n",
       "41             NaN            NaN                  NaN            NaN   \n",
       "42             NaN            NaN                  NaN            NaN   \n",
       "70             0.0            0.0                  0.0          102.0   \n",
       "\n",
       "                   AIRLINE SCHED_DEPARTURE_TIME ACTUAL_DEPARTURE_TIME  \\\n",
       "8   American Airlines Inc.            overnight             overnight   \n",
       "22        Spirit Air Lines            overnight             overnight   \n",
       "41        Spirit Air Lines            overnight             overnight   \n",
       "42  American Airlines Inc.            overnight                   NaN   \n",
       "70  American Airlines Inc.              morning               morning   \n",
       "\n",
       "   SCHED_ARRIVAL_TIME ACTUAL_ARRIVAL_TIME DISTANCE_BUCKET  DELAYED  \\\n",
       "8             morning             morning            Long        0   \n",
       "22            morning             morning            Long        0   \n",
       "41            morning             morning          Medium        1   \n",
       "42            morning                 NaN          Medium        1   \n",
       "70            morning             morning            Long        1   \n",
       "\n",
       "   FLIGHT_DATE SCHEDULED_DEPARTURE_DT SCHEDULED_ARRIVAL_DT  \n",
       "8   2015-01-01    2015-01-01 00:30:00  2015-01-01 05:45:00  \n",
       "22  2015-01-01    2015-01-01 01:03:00  2015-01-01 05:30:00  \n",
       "41  2015-01-01    2015-01-01 01:59:00  2015-01-01 05:02:00  \n",
       "42  2015-01-01    2015-01-01 02:00:00  2015-01-01 05:00:00  \n",
       "70  2015-01-01    2015-01-01 05:15:00  2015-01-01 08:56:00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the columns to make sure everything looks correct\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4484ad",
   "metadata": {},
   "source": [
    "### 1.3 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df50259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                           0\n",
       "MONTH                          0\n",
       "DAY                            0\n",
       "DAY_OF_WEEK                    0\n",
       "AIRLINE_CODE                   0\n",
       "FLIGHT_NUMBER                  0\n",
       "TAIL_NUMBER                 1014\n",
       "ORIGIN_AIRPORT                 0\n",
       "DESTINATION_AIRPORT            0\n",
       "SCHEDULED_DEPARTURE            0\n",
       "DEPARTURE_TIME             14180\n",
       "DEPARTURE_DELAY            14144\n",
       "TAXI_OUT                   14611\n",
       "WHEELS_OFF                 14678\n",
       "SCHEDULED_TIME                 1\n",
       "ELAPSED_TIME               16847\n",
       "AIR_TIME                   16847\n",
       "DISTANCE                       0\n",
       "WHEELS_ON                  15259\n",
       "TAXI_IN                    15046\n",
       "SCHEDULED_ARRIVAL              0\n",
       "ARRIVAL_TIME               15314\n",
       "ARRIVAL_DELAY              16847\n",
       "DIVERTED                       0\n",
       "CANCELLED                      0\n",
       "CANCELLATION_REASON       583787\n",
       "AIR_SYSTEM_DELAY          479999\n",
       "SECURITY_DELAY            479999\n",
       "AIRLINE_DELAY             479999\n",
       "LATE_AIRCRAFT_DELAY       479999\n",
       "WEATHER_DELAY             479999\n",
       "AIRLINE                        0\n",
       "SCHED_DEPARTURE_TIME           0\n",
       "ACTUAL_DEPARTURE_TIME      14180\n",
       "SCHED_ARRIVAL_TIME             0\n",
       "ACTUAL_ARRIVAL_TIME        15314\n",
       "DISTANCE_BUCKET                0\n",
       "DELAYED                        0\n",
       "FLIGHT_DATE                    0\n",
       "SCHEDULED_DEPARTURE_DT         0\n",
       "SCHEDULED_ARRIVAL_DT           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59883753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    583787\n",
       "1     14748\n",
       "Name: CANCELLED, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check cancellations\n",
    "df['CANCELLED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9c1b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove non-critical columns WHEELS_ON and WHEELS_OFF\n",
    "df = df.drop(['WHEELS_ON','WHEELS_OFF'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b50079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add category\n",
    "df['ACTUAL_DEPARTURE_TIME'] = df['ACTUAL_DEPARTURE_TIME'].cat.add_categories(['N'])\n",
    "df['ACTUAL_ARRIVAL_TIME'] = df['ACTUAL_ARRIVAL_TIME'].cat.add_categories(['N'])\n",
    "\n",
    "#fill missing values with 'N' for 'N/A'\n",
    "df['ACTUAL_DEPARTURE_TIME'] = df['ACTUAL_DEPARTURE_TIME'].fillna('N')\n",
    "df['ACTUAL_ARRIVAL_TIME'] = df['ACTUAL_ARRIVAL_TIME'].fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7dd8735",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert missing values to 'N' for 'N/A'\n",
    "df['CANCELLATION_REASON'] = df['CANCELLATION_REASON'].fillna('N')\n",
    "\n",
    "# Update missing values in times to 0. \n",
    "# Will be updating times to a binary (1 = yes action happened, 0 = no action happened)\n",
    "df['DEPARTURE_TIME'] = df['DEPARTURE_TIME'].fillna(0)\n",
    "\n",
    "# Change all non-null values to 1\n",
    "df.loc[(df.DEPARTURE_TIME != '0'), 'DEPARTURE_TIME'] = 1\n",
    "\n",
    "# Change column name to 'DEPARTED'\n",
    "df.rename(columns={'DEPARTURE_TIME': 'DEPARTED'}, inplace=True)\n",
    "\n",
    "# Update remaining columns using same logic\n",
    "cols = ['ARRIVAL_TIME']\n",
    "df[cols] = df[cols].fillna(0)\n",
    "df.loc[(df.ARRIVAL_TIME != '0'), 'ARRIVAL_TIME'] = 1\n",
    "df.rename(columns={'ARRIVAL_TIME': 'ARRIVED'}, inplace=True)\n",
    "\n",
    "# Fill missing values with 0\n",
    "cols = ['AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']\n",
    "df[cols] = df[cols].fillna(0)\n",
    "\n",
    "# Change remaining null values to 0 if flight was cancelled\n",
    "df.loc[(df.CANCELLED == 1), ('DEPARTURE_DELAY', 'TAXI_OUT', 'ELAPSED_TIME','AIR_TIME','TAXI_IN','ARRIVAL_DELAY')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b029b165",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                         0\n",
       "MONTH                        0\n",
       "DAY                          0\n",
       "DAY_OF_WEEK                  0\n",
       "AIRLINE_CODE                 0\n",
       "FLIGHT_NUMBER                0\n",
       "TAIL_NUMBER               1014\n",
       "ORIGIN_AIRPORT               0\n",
       "DESTINATION_AIRPORT          0\n",
       "SCHEDULED_DEPARTURE          0\n",
       "DEPARTED                     0\n",
       "DEPARTURE_DELAY              0\n",
       "TAXI_OUT                     0\n",
       "SCHEDULED_TIME               1\n",
       "ELAPSED_TIME              2099\n",
       "AIR_TIME                  2099\n",
       "DISTANCE                     0\n",
       "TAXI_IN                    298\n",
       "SCHEDULED_ARRIVAL            0\n",
       "ARRIVED                      0\n",
       "ARRIVAL_DELAY             2099\n",
       "DIVERTED                     0\n",
       "CANCELLED                    0\n",
       "CANCELLATION_REASON          0\n",
       "AIR_SYSTEM_DELAY             0\n",
       "SECURITY_DELAY               0\n",
       "AIRLINE_DELAY                0\n",
       "LATE_AIRCRAFT_DELAY          0\n",
       "WEATHER_DELAY                0\n",
       "AIRLINE                      0\n",
       "SCHED_DEPARTURE_TIME         0\n",
       "ACTUAL_DEPARTURE_TIME        0\n",
       "SCHED_ARRIVAL_TIME           0\n",
       "ACTUAL_ARRIVAL_TIME          0\n",
       "DISTANCE_BUCKET              0\n",
       "DELAYED                      0\n",
       "FLIGHT_DATE                  0\n",
       "SCHEDULED_DEPARTURE_DT       0\n",
       "SCHEDULED_ARRIVAL_DT         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values left\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e8f97c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    581688\n",
       "1     13733\n",
       "Name: CANCELLED, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop remaining missing values and check total cancels left\n",
    "df = df.dropna()\n",
    "df['CANCELLED'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef56362",
   "metadata": {},
   "source": [
    "### 1.4 Append Weather Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690466a",
   "metadata": {},
   "source": [
    "#### 1.4.1 Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e312d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in weather data from https://openweathermap.org\n",
    "df_weather = pd.read_csv('../Data/dfw_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ee71583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68238 entries, 0 to 68237\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   dt                   68238 non-null  int64  \n",
      " 1   dt_iso               68238 non-null  object \n",
      " 2   timezone             68238 non-null  int64  \n",
      " 3   city_name            68238 non-null  object \n",
      " 4   lat                  68238 non-null  float64\n",
      " 5   lon                  68238 non-null  float64\n",
      " 6   temp                 68238 non-null  float64\n",
      " 7   feels_like           68238 non-null  float64\n",
      " 8   temp_min             68238 non-null  float64\n",
      " 9   temp_max             68238 non-null  float64\n",
      " 10  pressure             68238 non-null  int64  \n",
      " 11  sea_level            0 non-null      float64\n",
      " 12  grnd_level           0 non-null      float64\n",
      " 13  humidity             68238 non-null  int64  \n",
      " 14  wind_speed           68238 non-null  float64\n",
      " 15  wind_deg             68238 non-null  int64  \n",
      " 16  rain_1h              7593 non-null   float64\n",
      " 17  rain_3h              1261 non-null   float64\n",
      " 18  snow_1h              247 non-null    float64\n",
      " 19  snow_3h              43 non-null     float64\n",
      " 20  clouds_all           68238 non-null  int64  \n",
      " 21  weather_id           68238 non-null  int64  \n",
      " 22  weather_main         68238 non-null  object \n",
      " 23  weather_description  68238 non-null  object \n",
      " 24  weather_icon         68238 non-null  object \n",
      "dtypes: float64(13), int64(7), object(5)\n",
      "memory usage: 13.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>dt_iso</th>\n",
       "      <th>timezone</th>\n",
       "      <th>city_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_level</th>\n",
       "      <th>grnd_level</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>rain_3h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>snow_3h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>weather_icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01 00:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.776664</td>\n",
       "      <td>-96.796988</td>\n",
       "      <td>46.98</td>\n",
       "      <td>35.71</td>\n",
       "      <td>42.80</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>11.50</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>801</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>02n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1388538000</td>\n",
       "      <td>2014-01-01 01:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.776664</td>\n",
       "      <td>-96.796988</td>\n",
       "      <td>44.51</td>\n",
       "      <td>32.25</td>\n",
       "      <td>40.64</td>\n",
       "      <td>48.20</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "      <td>13.80</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1388541600</td>\n",
       "      <td>2014-01-01 02:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.776664</td>\n",
       "      <td>-96.796988</td>\n",
       "      <td>42.76</td>\n",
       "      <td>32.70</td>\n",
       "      <td>39.00</td>\n",
       "      <td>46.40</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>9.22</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1388545200</td>\n",
       "      <td>2014-01-01 03:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.776664</td>\n",
       "      <td>-96.796988</td>\n",
       "      <td>42.58</td>\n",
       "      <td>31.23</td>\n",
       "      <td>37.40</td>\n",
       "      <td>46.94</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>11.50</td>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1388548800</td>\n",
       "      <td>2014-01-01 04:00:00 +0000 UTC</td>\n",
       "      <td>-21600</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.776664</td>\n",
       "      <td>-96.796988</td>\n",
       "      <td>41.85</td>\n",
       "      <td>29.91</td>\n",
       "      <td>37.04</td>\n",
       "      <td>44.96</td>\n",
       "      <td>1023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>12.66</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt                         dt_iso  timezone city_name        lat  \\\n",
       "0  1388534400  2014-01-01 00:00:00 +0000 UTC    -21600    Dallas  32.776664   \n",
       "1  1388538000  2014-01-01 01:00:00 +0000 UTC    -21600    Dallas  32.776664   \n",
       "2  1388541600  2014-01-01 02:00:00 +0000 UTC    -21600    Dallas  32.776664   \n",
       "3  1388545200  2014-01-01 03:00:00 +0000 UTC    -21600    Dallas  32.776664   \n",
       "4  1388548800  2014-01-01 04:00:00 +0000 UTC    -21600    Dallas  32.776664   \n",
       "\n",
       "         lon   temp  feels_like  temp_min  temp_max  pressure  sea_level  \\\n",
       "0 -96.796988  46.98       35.71     42.80     50.00      1025        NaN   \n",
       "1 -96.796988  44.51       32.25     40.64     48.20      1024        NaN   \n",
       "2 -96.796988  42.76       32.70     39.00     46.40      1024        NaN   \n",
       "3 -96.796988  42.58       31.23     37.40     46.94      1024        NaN   \n",
       "4 -96.796988  41.85       29.91     37.04     44.96      1023        NaN   \n",
       "\n",
       "   grnd_level  humidity  wind_speed  wind_deg  rain_1h  rain_3h  snow_1h  \\\n",
       "0         NaN        37       11.50       160      NaN      NaN      NaN   \n",
       "1         NaN        46       13.80       140      NaN      NaN      NaN   \n",
       "2         NaN        42        9.22       160      NaN      NaN      NaN   \n",
       "3         NaN        42       11.50       170      NaN      NaN      NaN   \n",
       "4         NaN        45       12.66       160      NaN      NaN      NaN   \n",
       "\n",
       "   snow_3h  clouds_all  weather_id weather_main weather_description  \\\n",
       "0      NaN          20         801       Clouds          few clouds   \n",
       "1      NaN           1         800        Clear        sky is clear   \n",
       "2      NaN           1         800        Clear        sky is clear   \n",
       "3      NaN           1         800        Clear        sky is clear   \n",
       "4      NaN           1         800        Clear        sky is clear   \n",
       "\n",
       "  weather_icon  \n",
       "0          02n  \n",
       "1          01n  \n",
       "2          01n  \n",
       "3          01n  \n",
       "4          01n  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the weather data\n",
    "df_weather.info()\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63253160",
   "metadata": {},
   "source": [
    "#### 1.4.2 Prepare Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "890c5d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_iso</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_level</th>\n",
       "      <th>grnd_level</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>rain_3h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>snow_3h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>46.98</td>\n",
       "      <td>35.71</td>\n",
       "      <td>42.80</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>11.50</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>801</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>44.51</td>\n",
       "      <td>32.25</td>\n",
       "      <td>40.64</td>\n",
       "      <td>48.20</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "      <td>13.80</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>42.76</td>\n",
       "      <td>32.70</td>\n",
       "      <td>39.00</td>\n",
       "      <td>46.40</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>9.22</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>42.58</td>\n",
       "      <td>31.23</td>\n",
       "      <td>37.40</td>\n",
       "      <td>46.94</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>11.50</td>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-01 04:00:00</td>\n",
       "      <td>41.85</td>\n",
       "      <td>29.91</td>\n",
       "      <td>37.04</td>\n",
       "      <td>44.96</td>\n",
       "      <td>1023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>12.66</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt_iso   temp  feels_like  temp_min  temp_max  pressure  \\\n",
       "0 2014-01-01 00:00:00  46.98       35.71     42.80     50.00      1025   \n",
       "1 2014-01-01 01:00:00  44.51       32.25     40.64     48.20      1024   \n",
       "2 2014-01-01 02:00:00  42.76       32.70     39.00     46.40      1024   \n",
       "3 2014-01-01 03:00:00  42.58       31.23     37.40     46.94      1024   \n",
       "4 2014-01-01 04:00:00  41.85       29.91     37.04     44.96      1023   \n",
       "\n",
       "   sea_level  grnd_level  humidity  wind_speed  wind_deg  rain_1h  rain_3h  \\\n",
       "0        NaN         NaN        37       11.50       160      NaN      NaN   \n",
       "1        NaN         NaN        46       13.80       140      NaN      NaN   \n",
       "2        NaN         NaN        42        9.22       160      NaN      NaN   \n",
       "3        NaN         NaN        42       11.50       170      NaN      NaN   \n",
       "4        NaN         NaN        45       12.66       160      NaN      NaN   \n",
       "\n",
       "   snow_1h  snow_3h  clouds_all  weather_id weather_main weather_description  \n",
       "0      NaN      NaN          20         801       Clouds          few clouds  \n",
       "1      NaN      NaN           1         800        Clear        sky is clear  \n",
       "2      NaN      NaN           1         800        Clear        sky is clear  \n",
       "3      NaN      NaN           1         800        Clear        sky is clear  \n",
       "4      NaN      NaN           1         800        Clear        sky is clear  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format dt_iso to match the SCHEDULED_DEPARTURE_DT and SCHEDULED_ARRIVAL_DT columns\n",
    "df_weather['dt_iso'] = pd.to_datetime(df_weather['dt_iso'].str[:19])\n",
    "\n",
    "# Weather columns to drop\n",
    "weather_drop = ['dt', 'timezone', 'city_name', 'lat', 'lon', 'weather_icon']\n",
    "\n",
    "# Drop dt column\n",
    "df_weather = df_weather.drop(columns = weather_drop)\n",
    "\n",
    "# Look at the data\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5be0431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to uppercase to match flight data\n",
    "df_weather.columns = df_weather.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fd291c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68238, 19)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f76cd",
   "metadata": {},
   "source": [
    "#### 1.4.3 Join Weather & Flight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2037b61d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SCHEDULED_DEPARTURE_DT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b91270218c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mdf_weather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SCHEDULED_DEPARTURE_DT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m               tolerance=pd.Timedelta('1h'))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge_asof\u001b[0;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mallow_exact_matches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_exact_matches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, axis, suffixes, copy, fill_method, how, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m   1674\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m             \u001b[0mfill_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         )\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, axis, suffixes, copy, fill_method, how)\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m             \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m             \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# factorize sorts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m         )\n\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m         \u001b[0;31m# note this function has side effects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0;31m# validate index types are the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SCHEDULED_DEPARTURE_DT'"
     ]
    }
   ],
   "source": [
    "# Join cases where origin airport is correct\n",
    "# https://pandas.pydata.org/pandas-docs/version/0.19.0/generated/pandas.merge_asof.html\n",
    "df_weather.rename(columns = {'ds_iso':'SCHEDULED_DEPARTURE_DT'}, inplace = True)\n",
    "\n",
    "pd.merge_asof(df, \n",
    "              df_weather,\n",
    "              on='SCHEDULED_DEPARTURE_DT',\n",
    "              tolerance=pd.Timedelta('1h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Look at the data\n",
    "# df.info()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c256670",
   "metadata": {},
   "source": [
    "#### 1.4.4 Drop Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77594b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make sure to delete date column after adding in weather data as we can't run model on timestamp data\n",
    "# df = df.drop(columns = ['FLIGHT_DATE', 'dt_iso'])\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb4653",
   "metadata": {},
   "source": [
    "### 1.5 Log Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174bc59a",
   "metadata": {},
   "source": [
    "As we discovered during Lab 1, the DEPARTURE_DELAY, ARRIVAL_DELAY, DISTANCE, TAXI_IN, ELAPSED_TIME, and AIR_TIME variables are siginificantly right-skewed with a large number of outliers. In order to normalize these values, we did a log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df[\"DEPARTURE_DELAY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0850e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df[\"ARRIVAL_DELAY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74735d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min(df[\"DISTANCE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebcb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df[\"TAXI_IN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cd6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df[\"ELAPSED_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df[\"AIR_TIME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89864797",
   "metadata": {},
   "source": [
    "MB comment: Because we have negative values in the departure and arrival delays, the below code that we have been using overwrites any negative value to 0. I have modified the code to keep 0 if the value is 0, but take the log for everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a35b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation keeping the 0 in the data sets \n",
    "#df[\"DEPARTURE_DELAY_log\"] = df[\"DEPARTURE_DELAY\"].map(lambda i: np.log1p(i) if i > 0 else 0) \n",
    "#df[\"ARRIVAL_DELAY_Log\"]   = df[\"ARRIVAL_DELAY\"].map(lambda i: np.log1p(i) if i > 0 else 0)\n",
    "#df[\"DISTANCE_log\"]        = df[\"DISTANCE\"].map(lambda i: np.log1p(i) if i > 0 else 0) \n",
    "#df[\"TAXI_IN_Log\"]         = df[\"TAXI_IN\"].map(lambda i: np.log1p(i) if i > 0 else 0)\n",
    "#df[\"ELAPSED_TIME_log\"]    = df[\"ELAPSED_TIME\"].map(lambda i: np.log1p(i) if i > 0 else 0) \n",
    "#df[\"AIR_TIME_log\"]        = df[\"AIR_TIME\"].map(lambda i: np.log1p(i) if i > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation keeping the 0 in the data sets. Because we have negative values, need to offset to make minimum\n",
    "# equal to zero and not a negative number. For the other vars, no need to run lambda function as min > 0 which improves\n",
    "# run time\n",
    "df[\"DEPARTURE_DELAY_log\"] = df[\"DEPARTURE_DELAY\"].map(lambda i: np.log(i + 68) if i != -68 else 0) \n",
    "df[\"ARRIVAL_DELAY_log\"]   = df[\"ARRIVAL_DELAY\"].map(lambda i: np.log(i + 87) if i != -87 else 0)\n",
    "df[\"DISTANCE_log\"]        = np.log(df[\"DISTANCE\"])\n",
    "df[\"TAXI_IN_log\"]         = np.log1p(df[\"TAXI_IN\"])\n",
    "df[\"ELAPSED_TIME_log\"]    = np.log1p(df[\"ELAPSED_TIME\"])\n",
    "df[\"AIR_TIME_log\"]        = np.log1p(df[\"AIR_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check calculations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501f3e0",
   "metadata": {},
   "source": [
    "### 1.6 Feature Removals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92448f",
   "metadata": {},
   "source": [
    "Here we remove redundant columns to further reduce the data size. Columns that are being removed:\n",
    "\n",
    "- `YEAR`: All rows are from 2015, no need to include this.\n",
    "- `AIRLINE`: We have AIRLINE_CODE which is the same information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['YEAR','AIRLINE']\n",
    "df = df.drop(columns = col_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b7170",
   "metadata": {},
   "source": [
    "### 1.7 Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400b7b1",
   "metadata": {},
   "source": [
    "We know that `TAIL_NUMBER`, `ORIGIN_AIRPORT`, and `DESTINATION_AIRPORT` contain a large number of unique values. Before proceeding, we wanted to check and see exactly how many of each we had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b602855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df['TAIL_NUMBER'].value_counts())\n",
    "print(df['ORIGIN_AIRPORT'].value_counts())\n",
    "print(df['DESTINATION_AIRPORT'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9f726",
   "metadata": {},
   "source": [
    "We have 3,700 different airplanes (TAIL_NUMBER) and 153 different airports (ORIGIN_AIRPORT and DESTINATION_AIRPORT). If we one-hot encode all of these, it would create way too many columns. We would also run the risk of not including a specific airport or tail number in our training data set which would cause an error if it is in our test data set. For that reason, let's set the cut-off to a minimum occurrence of 5 for tail numbers so that we have a greater likelihood of including it within either the train or test set. The minimum group size of the origin and destination airports is sufficiently large to avoid this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40394e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.groupby('TAIL_NUMBER').TAIL_NUMBER.transform(len) > 4]\n",
    "print(df['TAIL_NUMBER'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48da9d",
   "metadata": {},
   "source": [
    "This now reduces to 3,228 unique tail numbers. Hopefully a minimum count of 5 does not give us errors later on.\n",
    "\n",
    "Next, we will encode these variables. We are not one-hot encoding as there are still too many values. We know this will add some ordinality to the variables but it is simply not feasible to have 4000+ columns without moving to a cloud-based solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eadac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "df['ORIGIN_AIRPORT_encode'] = labelencoder.fit_transform(df['ORIGIN_AIRPORT'].astype('str'))\n",
    "df2 = df[['ORIGIN_AIRPORT','ORIGIN_AIRPORT_encode']]\n",
    "df2 = df2.drop_duplicates(subset=['ORIGIN_AIRPORT'], keep='last')\n",
    "\n",
    "df2.rename(columns={'ORIGIN_AIRPORT': 'DESTINATION_AIRPORT'}, inplace=True)\n",
    "df2.rename(columns={'ORIGIN_AIRPORT_encode': 'DESTINATION_AIRPORT_encode'}, inplace=True)\n",
    "\n",
    "df = pd.merge(df, df2, on='DESTINATION_AIRPORT', how = 'left')\n",
    "df.dropna(subset = [\"DESTINATION_AIRPORT_encode\"], inplace=True)\n",
    "\n",
    "df['TAIL_NUMBER_encode'] = labelencoder.fit_transform(df['TAIL_NUMBER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which value is DFW and DAL for later reference\n",
    "df[(df.ORIGIN_AIRPORT == 'DFW') | (df.ORIGIN_AIRPORT == 'DAL')].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b68ba92",
   "metadata": {},
   "source": [
    "`DFW` is `37` and `DAL` is `33`. We also have code above which makes sure the `ORIGIN_AIRPORT` and `DESTINATION_AIRPORT` encodings are the same value by airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ee697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original columns\n",
    "col_to_drop = ['TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT']\n",
    "df = df.drop(columns = col_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0610e",
   "metadata": {},
   "source": [
    "For the remaining categorical variables, we can one-hot encode as the number of unique values is significantly fewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b91b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd700b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total cancel check\n",
    "df['CANCELLED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901782b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "categorical_columns = ['AIRLINE_CODE', 'CANCELLATION_REASON', 'SCHED_DEPARTURE_TIME', \n",
    "                       'ACTUAL_DEPARTURE_TIME','SCHED_ARRIVAL_TIME', 'ACTUAL_ARRIVAL_TIME',\n",
    "                       'DISTANCE_BUCKET']\n",
    "\n",
    "for column in categorical_columns:\n",
    "  tempdf = pd.get_dummies(df[categorical_columns], prefix = categorical_columns, drop_first = True)\n",
    "  df_OHE = pd.merge(\n",
    "      left = df,\n",
    "      right = tempdf,\n",
    "      left_index=True,\n",
    "      right_index=True\n",
    "  )\n",
    "  df_OHE = df_OHE.drop(columns = categorical_columns)\n",
    "\n",
    "df_OHE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf415f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_OHE.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e19ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add response variable bucket for delay time\n",
    "delay_labels = ['Early_<0', 'On_Time_0-10', 'Late_11-30', 'Very_Late_31-60', 'Extremely_Late_61+']\n",
    "delay_bins   = [-np.inf, 0, 10, 30, 60, np.inf]\n",
    "df_OHE['DELAY_BUCKET'] = pd.cut(df_OHE['ARRIVAL_DELAY'],\n",
    "                               bins=delay_bins,\n",
    "                               labels=delay_labels)\n",
    "\n",
    "#check counts by bucket\n",
    "df_OHE['DELAY_BUCKET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode data set response variable\n",
    "df_OHE['DELAY_BUCKET'] = labelencoder.fit_transform(df_OHE['DELAY_BUCKET'].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59714f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check counts by bucket\n",
    "df_OHE['DELAY_BUCKET'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefdc19",
   "metadata": {},
   "source": [
    "### 1.8 Make New Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d897cb",
   "metadata": {},
   "source": [
    "Here, we will start to remove variables based on our desired response variable and then check correlations for further removals. We will drop the non-transformed versions of the below groups since it is duplicated and will naturally be correlated to the log version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c3037",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'DISTANCE', 'TAXI_IN', 'ELAPSED_TIME', 'AIR_TIME']\n",
    "df_OHE = df_OHE.drop(columns = col_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of our data for each new set\n",
    "df_cancel = df_OHE\n",
    "df_delay = df_OHE\n",
    "\n",
    "#drop delay bucket from cancellation set\n",
    "df_cancel = df_cancel.drop(columns = 'DELAY_BUCKET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ab34d",
   "metadata": {},
   "source": [
    "#### 1.8.1 Delay Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478bf86",
   "metadata": {},
   "source": [
    "We can remove several variables for our delay bucket group. We will filter out any cancelled flights, as these are not delayed. Then we can also remove `CANCELLED` and our `CANCELLATION_REASON` encoded columns. Because we don't know whether or not the flight will be delayed prior to the analysis, we will also remove `ACTUAL_ARRIVAL_TIME` and `ACTUAL_DEPARTURE_TIME` and all of of our other delay time related columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out cancelled flights\n",
    "df_delay = df_delay[df_delay.CANCELLED == 0]\n",
    "\n",
    "col_to_drop2 = ['CANCELLED', 'CANCELLATION_REASON_B', 'CANCELLATION_REASON_C', 'CANCELLATION_REASON_N', \n",
    "               'ACTUAL_DEPARTURE_TIME_morning', 'ACTUAL_DEPARTURE_TIME_afternoon', 'ACTUAL_DEPARTURE_TIME_evening',\n",
    "               'ACTUAL_DEPARTURE_TIME_N', 'ACTUAL_ARRIVAL_TIME_morning', 'ACTUAL_ARRIVAL_TIME_afternoon', \n",
    "                'SCHEDULED_DEPARTURE', 'SCHEDULED_ARRIVAL', 'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', \n",
    "                'ACTUAL_ARRIVAL_TIME_evening','ACTUAL_ARRIVAL_TIME_N','AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY', 'DELAYED', \n",
    "                'DEPARTURE_DELAY_log','ARRIVAL_DELAY_log', 'ELAPSED_TIME_log', 'DEPARTED', 'ARRIVED',\n",
    "               'TAXI_IN_log', 'AIR_TIME_log']\n",
    "\n",
    "df_delay = df_delay.drop(columns = col_to_drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965d6ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_delay.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b2de3a",
   "metadata": {},
   "source": [
    "#### 1.8.2 Cancelled data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d789f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42b302",
   "metadata": {},
   "source": [
    "For the cancellation data set, we need to remove the non-transformed versions of the variables we know will be correlated to their log version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop3 = ['DEPARTURE_DELAY_log','ARRIVAL_DELAY_log', 'ELAPSED_TIME_log',\n",
    "               'TAXI_IN_log', 'AIR_TIME_log', 'DISTANCE_log']\n",
    "\n",
    "df_cancel = df_cancel.drop(columns = col_to_drop3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total cancel check\n",
    "df_cancel['CANCELLED'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8aceb0",
   "metadata": {},
   "source": [
    "### 1.9 Check Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501b732",
   "metadata": {},
   "source": [
    "#### 1.9.1 Delay Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine correlation visually using Seaborn. \n",
    "# (Code adapted from 02. Data Visualization.ipynb)\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.set(style = \"darkgrid\") # one of the many styles to plot using\n",
    "\n",
    "f, ax = plt.subplots(figsize = (20, 20))\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(df_delay.corr(), cmap=cmap, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529af34",
   "metadata": {},
   "source": [
    "For our delay data set, we still see a high correlation between `DISTANCE_log` and `SCHEDULED_TIME` at a value of 0.92. Let's remove the `DISTANCE_log` value as we have distance buckets already. Let's also remove `DIVERTED` as the heat map shows us we have all `0` values in this column so it's not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop4 = ['DISTANCE_log', 'SCHEDULED_TIME', 'DIVERTED']\n",
    "\n",
    "df_delay = df_delay.drop(columns = col_to_drop4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b7d32",
   "metadata": {},
   "source": [
    "#### 1.9.2 Cancel Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20955eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine correlation visually using Seaborn. \n",
    "# (Code adapted from 02. Data Visualization.ipynb)\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.set(style = \"darkgrid\") # one of the many styles to plot using\n",
    "\n",
    "f, ax = plt.subplots(figsize = (20, 20))\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(df_cancel.corr(), cmap=cmap, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix with absolute values only\n",
    "corr_matrix_abs = df_cancel.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix_abs.where(np.triu(np.ones(corr_matrix_abs.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find features with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff383a2",
   "metadata": {},
   "source": [
    "For the columns that have a very high correlation, we will retain these columns for now due to their perceived importance in our analysis and will use feature selection techniques to remove if deemed necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cbb6d",
   "metadata": {},
   "source": [
    "### 1.10 Final Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5f582",
   "metadata": {},
   "source": [
    "- **[5 points]** Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b076b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save data\n",
    "# df_cancel.to_csv('../Data/df_cancel.csv', index=False)\n",
    "# df_delay.to_csv('../Data/df_delay.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86909c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load data from here to save time\n",
    "# df_cancel = pd.read_csv('../Data/df_cancel.csv')\n",
    "# df_delay = pd.read_csv('../Data/df_delay.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f55ebe",
   "metadata": {},
   "source": [
    "  \n",
    "#### Modeling and Evaluation (70 points total)\n",
    "\n",
    "- **[10 points]** Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "- **[10 points]** Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate.\n",
    "- **[20 points]** Create three different classification/regression models (e.g., random forest, KNN, and SVM). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric.\n",
    "- **[10 points]** Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "- **[10 points]** Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods.\n",
    "- **[10 points]** Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "\n",
    "#### Deployment (5 points total)\n",
    "\n",
    "- **[5 points]** How useful is your model for interested parties (i.e., the companies or\n",
    "organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "\n",
    "#### Exceptional Work (10 points total)\n",
    "\n",
    "- You have free reign to provide additional modeling.\n",
    "- One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
