{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34d1adc",
   "metadata": {},
   "source": [
    "# Mini-Project: SVM & Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478385b",
   "metadata": {},
   "source": [
    "Matt Farrow, Amber Clark, Blake Freeman, Megan Ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec0927",
   "metadata": {},
   "source": [
    "## **2015 Flight Delays and Cancellations**\n",
    "Data Source: [Kaggle](https://www.kaggle.com/usdot/flight-delays?select=flights.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db91e3",
   "metadata": {},
   "source": [
    "## Logistic Regression & Support Vector Machine Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e6f7b",
   "metadata": {},
   "source": [
    "[50 points] Create a logistic regression model and a support vector machine model for the\n",
    "classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a9195",
   "metadata": {},
   "source": [
    "### Prep Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a317f",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336a9416",
   "metadata": {
    "id": "458f1645"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "# Import time-based columns as strings to keep leading zeroes\n",
    "dtype_t = {'SCHEDULED_DEPARTURE': str,\n",
    "           'DEPARTURE_TIME': str,\n",
    "           'WHEELS_OFF': str,\n",
    "           'SCHEDULED_TIME': str,\n",
    "           'WHEELS_ON': str,\n",
    "           'SCHEDULED_ARRIVAL': str,\n",
    "           'ARRIVAL_TIME': str\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9dd56",
   "metadata": {},
   "source": [
    "#### Read & Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b14b119b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattfarrow/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3166: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read in the data directly using Pandas\n",
    "airlines = pd.read_csv('../Data/airlines.csv')\n",
    "airports = pd.read_csv('../Data/airports.csv')\n",
    "flights  = pd.read_csv('../Data/flights.csv', dtype = dtype_t)\n",
    "\n",
    "# Read in the data directly from GitHub\n",
    "# airlines = pd.read_csv('https://raw.githubusercontent.com/mattfarrow1/7331-machine-learning-1/main/Data/airlines.csv')\n",
    "# airports = pd.read_csv('https://raw.githubusercontent.com/mattfarrow1/7331-machine-learning-1/main/Data/airports.csv')\n",
    "# flights  = pd.read_csv('https://media.githubusercontent.com/media/mattfarrow1/7331-machine-learning-1/main/Data/flights.csv', dtype = dtype_t)\n",
    "\n",
    "# Rename columns in preparation for merge\n",
    "airlines.rename(columns={'IATA_CODE': 'AIRLINE_CODE'}, inplace=True)\n",
    "flights.rename(columns={'AIRLINE': 'AIRLINE_CODE'}, inplace=True)\n",
    "\n",
    "# Merge data together\n",
    "df = pd.merge(flights, airlines, on='AIRLINE_CODE', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01cb48",
   "metadata": {},
   "source": [
    "#### Format Date & Time-Based Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17842a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string columns to datetime\n",
    "cols = [\"SCHEDULED_DEPARTURE\", \n",
    "        \"DEPARTURE_TIME\", \n",
    "        \"WHEELS_OFF\",  \n",
    "        \"WHEELS_ON\", \n",
    "        \"SCHEDULED_ARRIVAL\", \n",
    "        \"ARRIVAL_TIME\"]\n",
    "\n",
    "# Coerce time-based columns to an Hour:Minute format\n",
    "df[cols] = df[cols].apply(pd.to_datetime, format = '%H%M', errors='coerce')\n",
    "\n",
    "# Convert YMD into a single date\n",
    "# Source: https://stackoverflow.com/questions/54487059/pandas-how-to-create-a-single-date-column-from-columns-containing-year-month\n",
    "df['FLIGHT_DATE'] = pd.to_datetime([f'{y}-{m}-{d}' for y, m, d in zip(df.YEAR, df.MONTH, df.DAY)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c8557",
   "metadata": {},
   "source": [
    "#### Exclude Cancelled Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b58c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['CANCELLED'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad60a41",
   "metadata": {},
   "source": [
    "#### Deal with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a946a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing delay values with 0\n",
    "cols = ['AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']\n",
    "df[cols] = df[cols].fillna(0)\n",
    "\n",
    "# Drop unnecessary columns: \n",
    "#    CANCELLATION_REASON since all cancelled flights are gone\n",
    "#    YEAR, MONTH, DAY since those have been converted to a single date already\n",
    "#    AIRLINE_CODE since AIRLINE has been merged in\n",
    "#    SCHEDULED_TIME since that's still an object\n",
    "df = df.drop(['YEAR', 'MONTH', 'DAY', 'CANCELLED', 'CANCELLATION_REASON', 'AIRLINE_CODE', 'SCHEDULED_TIME'], axis=1)\n",
    "\n",
    "# There are 15,187 remaining rows with missing values for ARRIVAL_DELAY. We'll remove remaining null values.\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092066f",
   "metadata": {},
   "source": [
    "#### Bucket Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0ae335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight Distance\n",
    "distance_labels = ['Short', 'Medium', 'Long']\n",
    "distance_bins   = [1, 100, 1000, np.inf]\n",
    "df['DISTANCE_BUCKET'] = pd.cut(df['DISTANCE'],\n",
    "                               bins=distance_bins,\n",
    "                               labels=distance_labels)\n",
    "\n",
    "# Arrival Delay\n",
    "delay_labels = ['Early', 'On-Time', '30-59', '60-89', '90-119', '120+']\n",
    "delay_bins   = [-np.inf, 0, 30, 60, 90, 120, np.inf]\n",
    "df['ARRIVAL_DELAY_BUCKET'] = pd.cut(df['ARRIVAL_DELAY'],\n",
    "                                    bins=delay_bins,\n",
    "                                    labels=delay_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e6f88",
   "metadata": {},
   "source": [
    "#### Create Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8973e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column where the arrival_delay > 0 means it's delayed(=1) and if <= 0 it's not delayed(=0)\n",
    "get_delay = lambda x: 0 if x <= 0 else 1\n",
    "df['DELAYED'] = df.ARRIVAL_DELAY.apply(get_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672b9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5708334 entries, 0 to 5819078\n",
      "Data columns (total 29 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   DAY_OF_WEEK           int64         \n",
      " 1   FLIGHT_NUMBER         int64         \n",
      " 2   TAIL_NUMBER           object        \n",
      " 3   ORIGIN_AIRPORT        object        \n",
      " 4   DESTINATION_AIRPORT   object        \n",
      " 5   SCHEDULED_DEPARTURE   datetime64[ns]\n",
      " 6   DEPARTURE_TIME        datetime64[ns]\n",
      " 7   DEPARTURE_DELAY       float64       \n",
      " 8   TAXI_OUT              float64       \n",
      " 9   WHEELS_OFF            datetime64[ns]\n",
      " 10  ELAPSED_TIME          float64       \n",
      " 11  AIR_TIME              float64       \n",
      " 12  DISTANCE              int64         \n",
      " 13  WHEELS_ON             datetime64[ns]\n",
      " 14  TAXI_IN               float64       \n",
      " 15  SCHEDULED_ARRIVAL     datetime64[ns]\n",
      " 16  ARRIVAL_TIME          datetime64[ns]\n",
      " 17  ARRIVAL_DELAY         float64       \n",
      " 18  DIVERTED              int64         \n",
      " 19  AIR_SYSTEM_DELAY      float64       \n",
      " 20  SECURITY_DELAY        float64       \n",
      " 21  AIRLINE_DELAY         float64       \n",
      " 22  LATE_AIRCRAFT_DELAY   float64       \n",
      " 23  WEATHER_DELAY         float64       \n",
      " 24  AIRLINE               object        \n",
      " 25  FLIGHT_DATE           datetime64[ns]\n",
      " 26  DISTANCE_BUCKET       category      \n",
      " 27  ARRIVAL_DELAY_BUCKET  category      \n",
      " 28  DELAYED               int64         \n",
      "dtypes: category(2), datetime64[ns](7), float64(11), int64(5), object(4)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05544a2a",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7dea02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: datagy.io/pandas-get-dummies/\n",
    "\n",
    "one_hot_columns = ['TAIL_NUMBER',\n",
    "                   'ORIGIN_AIRPORT', \n",
    "                   'DESTINATION_AIRPORT',\n",
    "                   'AIRLINE',\n",
    "                  'DISTANCE_BUCKET',\n",
    "                  'ARRIVAL_DELAY_BUCKET']\n",
    "\n",
    "for column in one_hot_columns:\n",
    "    tempdf = pd.get_dummies(df[column], prefix=column)\n",
    "    \n",
    "    df = pd.merge(\n",
    "        left = df,\n",
    "        right = tempdf,\n",
    "        left_index = True,\n",
    "        right_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84fd860e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5708334, 6806)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b883c8",
   "metadata": {},
   "source": [
    "#### Sample 1% of Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f415350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72f3fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57083, 6806)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452505ef",
   "metadata": {},
   "source": [
    "#### Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff06bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=1, random_state=42, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Split response variable from rest of the data:\n",
    "if 'DELAYED' in df_sample:\n",
    "    y = df_sample['DELAYED'].values # get the labels we want\n",
    "    del df_sample['DELAYED']        # get rid of the class label\n",
    "    X = df_sample.values            # use everything else to predict\n",
    "\n",
    "# Split using cross validation\n",
    "num_cv_iterations = 1\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations, test_size  = 0.2, random_state = 42)\n",
    "# cv_object = StratifiedKFold(n_splits = num_cv_iterations, shuffle = True, random_state = 42)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d54f2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb135b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45666, 6805), (11417, 6805), (45666,), (11417,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8dc4e",
   "metadata": {},
   "source": [
    "#### Create SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d4a14c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 12 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattfarrow/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'N882AS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    169\u001b[0m             X, y = self._validate_data(X, y, dtype=np.float64,\n\u001b[1;32m    170\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                                        accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'N882AS'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Create a Linear regression object and perform a grid search to find the best parameters\n",
    "reg = SVC()\n",
    "\n",
    "#Set up SVC parameters to test \n",
    "costs = [0.01, 3.0]\n",
    "gamma = ['scale','auto']\n",
    "kernels = ['poly', 'rbf', 'sigmoid']\n",
    "parameters = {'C': costs, 'gamma' : gamma, 'kernel': kernels}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svmGridSearch = GridSearchCV(estimator=reg,\n",
    "                             n_jobs=-1, # automatically use every available core\n",
    "                             verbose=1, # low verbosity\n",
    "                             param_grid=parameters,\n",
    "                             cv=cv_object,\n",
    "                             scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "svmGridSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best estimator parameters\n",
    "svmGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed72104",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use the best object\n",
    "classifierEst2 = svmGridSearch.best_estimator_\n",
    "\n",
    "# Evaluate the SVM estimator above using pre-defined cross validation and scoring metrics. \n",
    "EvaluateClassifierEstimator(classifierEst2, X_train, y_train, cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953b8a2",
   "metadata": {},
   "source": [
    "## Advantages of Each Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9734e",
   "metadata": {
    "tags": []
   },
   "source": [
    "[10 points] Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5970f8",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e74e27",
   "metadata": {},
   "source": [
    "[30 points] Use the weights from logistic regression to interpret the importance of different features for each classification task. Explain your interpretation in detail. Why do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d70745",
   "metadata": {},
   "source": [
    "## Support Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6686e",
   "metadata": {},
   "source": [
    "[10 points] Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
