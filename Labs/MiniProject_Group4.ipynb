{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34d1adc",
   "metadata": {},
   "source": [
    "# Mini-Project: SVM & Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478385b",
   "metadata": {},
   "source": [
    "Matt Farrow, Amber Clark, Blake Freeman, Megan Ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec0927",
   "metadata": {},
   "source": [
    "## **2015 Flight Delays and Cancellations**\n",
    "Data Source: [Kaggle](https://www.kaggle.com/usdot/flight-delays?select=flights.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db91e3",
   "metadata": {},
   "source": [
    "## Logistic Regression & Support Vector Machine Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e6f7b",
   "metadata": {},
   "source": [
    "[50 points] Create a logistic regression model and a support vector machine model for the\n",
    "classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a9195",
   "metadata": {},
   "source": [
    "### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336a9416",
   "metadata": {
    "id": "458f1645"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattfarrow/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3166: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import altair as alt\n",
    "\n",
    "# Due to the way these columns are formatted, we want to keep the leading zeros during our import. Later on will convert them to a time format.\n",
    "dtype_t = {'SCHEDULED_DEPARTURE': str,\n",
    "           'DEPARTURE_TIME': str,\n",
    "           'WHEELS_OFF': str,\n",
    "           'SCHEDULED_TIME': str,\n",
    "           'WHEELS_ON': str,\n",
    "           'SCHEDULED_ARRIVAL': str,\n",
    "           'ARRIVAL_TIME': str\n",
    "          }\n",
    "\n",
    "# Read in the data directly\n",
    "# Read in the data using Pandas\n",
    "airlines = pd.read_csv('../Data/airlines.csv')\n",
    "airports = pd.read_csv('../Data/airports.csv')\n",
    "flights  = pd.read_csv('../Data/flights.csv', dtype = dtype_t)\n",
    "\n",
    "# Read in the data directly from GitHub\n",
    "# airlines = pd.read_csv('https://raw.githubusercontent.com/mattfarrow1/7331-machine-learning-1/main/Data/airlines.csv')\n",
    "# airports = pd.read_csv('https://raw.githubusercontent.com/mattfarrow1/7331-machine-learning-1/main/Data/airports.csv')\n",
    "# flights  = pd.read_csv('https://media.githubusercontent.com/media/mattfarrow1/7331-machine-learning-1/main/Data/flights.csv', dtype = dtype_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c2c6d8",
   "metadata": {
    "id": "2009e446"
   },
   "outputs": [],
   "source": [
    "# Rename columns in preparation for merge\n",
    "airlines.rename(columns={'IATA_CODE': 'AIRLINE_CODE'}, inplace=True)\n",
    "flights.rename(columns={'AIRLINE': 'AIRLINE_CODE'}, inplace=True)\n",
    "\n",
    "# Merge data together\n",
    "df = pd.merge(flights, airlines, on='AIRLINE_CODE', how = 'left')\n",
    "\n",
    "# Convert string columns to datetime\n",
    "cols = [\"SCHEDULED_DEPARTURE\", \n",
    "   \"DEPARTURE_TIME\", \n",
    "   \"WHEELS_OFF\",  \n",
    "   \"WHEELS_ON\", \n",
    "   \"SCHEDULED_ARRIVAL\", \n",
    "   \"ARRIVAL_TIME\"]\n",
    "\n",
    "df[cols] = df[cols].apply(pd.to_datetime, format = '%H%M', errors='coerce')\n",
    "\n",
    "# Convert YMD into a single date\n",
    "# Source: https://stackoverflow.com/questions/54487059/pandas-how-to-create-a-single-date-column-from-columns-containing-year-month\n",
    "df['FLIGHT_DATE'] = pd.to_datetime([f'{y}-{m}-{d}' for y, m, d in zip(df.YEAR, df.MONTH, df.DAY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a63d22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "Yc3zGo9VFNCE",
    "outputId": "8a351e87-548d-4040-df41-6db4cd53d2f8"
   },
   "outputs": [],
   "source": [
    "# Convert missing values to 'N' for 'N/A'\n",
    "df['CANCELLATION_REASON'] = df['CANCELLATION_REASON'].fillna('N')\n",
    "\n",
    "# Source: datagy.io/pandas-get-dummies/\n",
    "# One hot encode - removing to save memory\n",
    "\n",
    "#one_hot_columns = ['CANCELLATION_REASON']\n",
    "\n",
    "#for column in one_hot_columns:\n",
    "#  tempdf = pd.get_dummies(df[column], prefix=column)\n",
    "#\n",
    "#  df = pd.merge(\n",
    "#      left = df,\n",
    "#      right = tempdf,\n",
    "#      left_index = True,\n",
    "#      right_index = True,\n",
    "#  )\n",
    "\n",
    "#  df = df.drop(columns=column)\n",
    "\n",
    "# Update missing values in times to 0. \n",
    "# Will be updating times to a binary (1 = yes action happened, 0 = no action happened)\n",
    "df['DEPARTURE_TIME'] = df['DEPARTURE_TIME'].fillna(0)\n",
    "\n",
    "# Change all non-null values to 1\n",
    "df.loc[(df.DEPARTURE_TIME != '0'), 'DEPARTURE_TIME'] = 1\n",
    "\n",
    "# Change column name to 'DEPARTED'\n",
    "df.rename(columns={'DEPARTURE_TIME': 'DEPARTED'}, inplace=True)\n",
    "\n",
    "# Update remaining columns using same logic\n",
    "cols = ['WHEELS_OFF','WHEELS_ON','ARRIVAL_TIME']\n",
    "df[cols] = df[cols].fillna(0)\n",
    "df.loc[(df.WHEELS_OFF != '0'), 'WHEELS_OFF'] = 1\n",
    "df.loc[(df.WHEELS_ON != '0'), 'WHEELS_ON'] = 1\n",
    "df.loc[(df.ARRIVAL_TIME != '0'), 'ARRIVAL_TIME'] = 1\n",
    "df.rename(columns={'ARRIVAL_TIME': 'ARRIVED'}, inplace=True)\n",
    "\n",
    "# Fill missing values with 0\n",
    "cols = ['AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']\n",
    "df[cols] = df[cols].fillna(0)\n",
    "\n",
    "# Change remaining null values to 0 if flight was cancelled\n",
    "df.loc[(df.CANCELLED == 1), ('DEPARTURE_DELAY', 'TAXI_OUT', 'ELAPSED_TIME','AIR_TIME','TAXI_IN','ARRIVAL_DELAY')] = 0\n",
    "\n",
    "# Remove remaining null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abfc456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transformation keeping the 0 in the data sets \n",
    "df[\"DEPARTURE_DELAY_log\"] = df[\"DEPARTURE_DELAY\"].map(lambda i: np.log1p(i) if i > 0 else 0) \n",
    "df[\"ARRIVAL_DELAY_Log\"]   = df[\"ARRIVAL_DELAY\"].map(lambda i: np.log1p(i) if i > 0 else 0)\n",
    "df[\"DISTANCE_log\"]        = df[\"DISTANCE\"].map(lambda i: np.log1p(i) if i > 0 else 0) \n",
    "df[\"TAXI_IN_Log\"]         = df[\"TAXI_IN\"].map(lambda i: np.log1p(i) if i > 0 else 0)\n",
    "df[\"ELAPSED_TIME_log\"]    = df[\"ELAPSED_TIME\"].map(lambda i: np.log1p(i) if i > 0 else 0) \n",
    "df[\"AIR_TIME_log\"]        = df[\"AIR_TIME\"].map(lambda i: np.log1p(i) if i > 0 else 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953b8a2",
   "metadata": {},
   "source": [
    "## Advantages of Each Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9734e",
   "metadata": {
    "tags": []
   },
   "source": [
    "[10 points] Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5970f8",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e74e27",
   "metadata": {},
   "source": [
    "[30 points] Use the weights from logistic regression to interpret the importance of different features for each classification task. Explain your interpretation in detail. Why do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d70745",
   "metadata": {},
   "source": [
    "## Support Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6686e",
   "metadata": {},
   "source": [
    "[10 points] Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
