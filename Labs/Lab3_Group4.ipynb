{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc02de2a",
   "metadata": {},
   "source": [
    "# Lab Three: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95ce89",
   "metadata": {},
   "source": [
    "Matt Farrow, Amber Clark, Blake Freeman, Megan Ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92470e4b",
   "metadata": {},
   "source": [
    "## **2015 Flight Delays and Cancellations**\n",
    "Data Source: [Kaggle](https://www.kaggle.com/usdot/flight-delays?select=flights.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a82361d",
   "metadata": {},
   "source": [
    "Our data set consists of over 5 million rows of flight information in the domestic United States for the year of 2015. In order to optimize our modeling time, we have narrowed the scope of our classification tasks to the Dallas area only (Dallas Love Field and DFW airports). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb8aee",
   "metadata": {},
   "source": [
    "## Rubric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09044e77",
   "metadata": {},
   "source": [
    "### [Business Understanding](#Business-Understanding) (10 points total)\n",
    "\n",
    "- [10 points] Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm? Why does your chosen validation method make sense for this specific dataset and the stakeholders needs?\n",
    "\n",
    "### [Data Understanding](#Data-Understanding) (20 points total)\n",
    "\n",
    "#### [Data Understanding 1](#Data-Understanding-1)\n",
    "\n",
    "- [10 points] Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?\n",
    "\n",
    "#### [Data Understanding 2](#Data-Understanding-2)\n",
    "\n",
    "- [10 points] Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.\n",
    "\n",
    "### [Modeling and Evaluation](#Modeling-and-Evaluation) (50 points total)\n",
    "\n",
    "Different tasks will require different evaluation methods. Be as thorough as possible when analyzing the data you have chosen and use visualizations of the results to explain the performance and expected outcomes whenever possible. Guide the reader through your analysis with plenty of discussion of the results.\n",
    "\n",
    "#### Option A: Cluster Analysis\n",
    "\n",
    "- Perform cluster analysis using several clustering methods\n",
    "- How did you determine a suitable number of clusters for each method?\n",
    "- Use internal and/or external validation measures to describe and compare the clusterings and the clusters (some visual methods would be good).\n",
    "- Describe your results. What findings are the most interesting and why?\n",
    "\n",
    "#### [Modeling and Evaluation 1](#Modeling-and-Evaluation-1)\n",
    "\n",
    "- Train and adjust parameters\n",
    "\n",
    "#### [Modeling and Evaluation 2](#Modeling-and-Evaluation-2)\n",
    "\n",
    "- Evaluate and compare\n",
    "\n",
    "#### [Modeling and Evaluation 3](#Modeling-and-Evaluation-3)\n",
    "\n",
    "- Visualize results\n",
    "\n",
    "#### [Modeling and Evaluation 4](#Modeling-and-Evaluation-4)\n",
    "\n",
    "- Summarise the ramifications\n",
    "\n",
    "### [Deployment](#Deployment) (10 points total)\n",
    "\n",
    "Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling?\n",
    "\n",
    "- How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)?\n",
    "- How would your deploy your model for interested parties?\n",
    "- What other data should be collected?\n",
    "- How often would the model need to be updated, etc.?\n",
    "\n",
    "### [Exceptional Work](#Exceptional-Work) (10 points total)\n",
    "\n",
    "You have free reign to provide additional analyses or combine analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d101b",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "Jump to [top](#Rubric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad2c01",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "Jump to [top](#Rubric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07994c16",
   "metadata": {},
   "source": [
    "## Data Understanding 1\n",
    "Jump to [top](#Rubric)\n",
    "\n",
    "> Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689487c2",
   "metadata": {},
   "source": [
    "The initial data pre-processing has already been covered in Labs 1, 2, and the Mini-Lab. Here we have collapsed our code as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f629c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from datetime import datetime\n",
    "import altair as alt\n",
    "import datetime\n",
    "\n",
    "# Machine learning\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfb947",
   "metadata": {},
   "source": [
    "## [Jump to Clean Data](#Final-Data-Set)\n",
    "\n",
    "Clicking this link will skip over the cleanup work and let you get started with the final data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a66eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Due to the way these columns are formatted, we want to keep the leading zeros during our import. \n",
    "# Later on will convert them to a time format.\n",
    "dtype_t = {'SCHEDULED_DEPARTURE': str,\n",
    "           'DEPARTURE_TIME': str,\n",
    "           'WHEELS_OFF': str,\n",
    "           'SCHEDULED_TIME': str,\n",
    "           'WHEELS_ON': str,\n",
    "           'SCHEDULED_ARRIVAL': str,\n",
    "           'ARRIVAL_TIME': str\n",
    "          }\n",
    "\n",
    "# Read in the data directly\n",
    "airlines = pd.read_csv('../Data/airlines.csv')\n",
    "airports = pd.read_csv('../Data/airports.csv')\n",
    "flights  = pd.read_csv('../Data/flights.csv', dtype = dtype_t)\n",
    "\n",
    "# Read in the data directly from GitHub\n",
    "# airlines = pd.read_csv('https://raw.githubusercontent.com/mattfarrow1/7331-machine-learning-1/main/Data/airlines.csv')\n",
    "# airports = pd.read_csv('https://raw.githubusercontent.com/mattfarrow1/7331-machine-learning-1/main/Data/airports.csv')\n",
    "# flights  = pd.read_csv('https://media.githubusercontent.com/media/mattfarrow1/7331-machine-learning-1/main/Data/flights.csv', dtype = dtype_t)\n",
    "\n",
    "# Rename columns in preparation for merge\n",
    "airlines.rename(columns={'IATA_CODE': 'AIRLINE_CODE'}, inplace=True)\n",
    "flights.rename(columns={'AIRLINE': 'AIRLINE_CODE'}, inplace=True)\n",
    "\n",
    "# Merge data together\n",
    "df = pd.merge(flights, airlines, on='AIRLINE_CODE', how = 'left')\n",
    "\n",
    "# Subset to DFW Area\n",
    "df = df[(df.ORIGIN_AIRPORT == 'DFW') | (df.ORIGIN_AIRPORT == 'DAL')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81b894",
   "metadata": {},
   "source": [
    "#### Create New Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da81f544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE_CODE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>DEPARTURE_TIME</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>SCHEDULED_TIME</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>SCHED_DEPARTURE_TIME</th>\n",
       "      <th>ACTUAL_DEPARTURE_TIME</th>\n",
       "      <th>SCHED_ARRIVAL_TIME</th>\n",
       "      <th>ACTUAL_ARRIVAL_TIME</th>\n",
       "      <th>DISTANCE_BUCKET</th>\n",
       "      <th>DELAYED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1057</td>\n",
       "      <td>N3ASAA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0515</td>\n",
       "      <td>0703</td>\n",
       "      <td>108.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0718</td>\n",
       "      <td>161</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1121</td>\n",
       "      <td>1031</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0856</td>\n",
       "      <td>1038</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>1890</td>\n",
       "      <td>N377DA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0545</td>\n",
       "      <td>0603</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0616</td>\n",
       "      <td>124</td>\n",
       "      <td>104.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>731</td>\n",
       "      <td>0842</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0849</td>\n",
       "      <td>0847</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delta Air Lines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>72</td>\n",
       "      <td>N5EKAA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>MCO</td>\n",
       "      <td>0600</td>\n",
       "      <td>0606</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0624</td>\n",
       "      <td>145</td>\n",
       "      <td>142.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>985</td>\n",
       "      <td>0924</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0925</td>\n",
       "      <td>0928</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1100</td>\n",
       "      <td>N3GWAA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>LGA</td>\n",
       "      <td>0600</td>\n",
       "      <td>0554</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0627</td>\n",
       "      <td>190</td>\n",
       "      <td>191.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1389</td>\n",
       "      <td>1001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>1005</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>overnight</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>Long</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>3015</td>\n",
       "      <td>N825MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>BTR</td>\n",
       "      <td>0600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Eagle Airlines Inc.</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE_CODE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "70   2015      1    1            4           AA           1057      N3ASAA   \n",
       "124  2015      1    1            4           DL           1890      N377DA   \n",
       "203  2015      1    1            4           AA             72      N5EKAA   \n",
       "209  2015      1    1            4           AA           1100      N3GWAA   \n",
       "310  2015      1    1            4           MQ           3015      N825MQ   \n",
       "\n",
       "    ORIGIN_AIRPORT DESTINATION_AIRPORT SCHEDULED_DEPARTURE DEPARTURE_TIME  \\\n",
       "70             DFW                 MIA                0515           0703   \n",
       "124            DFW                 ATL                0545           0603   \n",
       "203            DFW                 MCO                0600           0606   \n",
       "209            DFW                 LGA                0600           0554   \n",
       "310            DFW                 BTR                0600            NaN   \n",
       "\n",
       "     DEPARTURE_DELAY  TAXI_OUT WHEELS_OFF SCHEDULED_TIME  ELAPSED_TIME  \\\n",
       "70             108.0      15.0       0718            161         155.0   \n",
       "124             18.0      13.0       0616            124         104.0   \n",
       "203              6.0      18.0       0624            145         142.0   \n",
       "209             -6.0      33.0       0627            190         191.0   \n",
       "310              NaN       NaN        NaN             78           NaN   \n",
       "\n",
       "     AIR_TIME  DISTANCE WHEELS_ON  TAXI_IN SCHEDULED_ARRIVAL ARRIVAL_TIME  \\\n",
       "70      133.0      1121      1031      7.0              0856         1038   \n",
       "124      86.0       731      0842      5.0              0849         0847   \n",
       "203     120.0       985      0924      4.0              0925         0928   \n",
       "209     154.0      1389      1001      4.0              1010         1005   \n",
       "310       NaN       383       NaN      NaN              0718          NaN   \n",
       "\n",
       "     ARRIVAL_DELAY  DIVERTED  CANCELLED CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n",
       "70           102.0         0          0                 NaN               0.0   \n",
       "124           -2.0         0          0                 NaN               NaN   \n",
       "203            3.0         0          0                 NaN               NaN   \n",
       "209           -5.0         0          0                 NaN               NaN   \n",
       "310            NaN         0          1                   B               NaN   \n",
       "\n",
       "     SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \\\n",
       "70              0.0            0.0                  0.0          102.0   \n",
       "124             NaN            NaN                  NaN            NaN   \n",
       "203             NaN            NaN                  NaN            NaN   \n",
       "209             NaN            NaN                  NaN            NaN   \n",
       "310             NaN            NaN                  NaN            NaN   \n",
       "\n",
       "                          AIRLINE SCHED_DEPARTURE_TIME ACTUAL_DEPARTURE_TIME  \\\n",
       "70         American Airlines Inc.            overnight               morning   \n",
       "124          Delta Air Lines Inc.            overnight               morning   \n",
       "203        American Airlines Inc.            overnight               morning   \n",
       "209        American Airlines Inc.            overnight             overnight   \n",
       "310  American Eagle Airlines Inc.            overnight                   NaN   \n",
       "\n",
       "    SCHED_ARRIVAL_TIME ACTUAL_ARRIVAL_TIME DISTANCE_BUCKET  DELAYED  \n",
       "70             morning             morning            Long        1  \n",
       "124            morning             morning          Medium        0  \n",
       "203            morning             morning          Medium        1  \n",
       "209            morning             morning            Long        0  \n",
       "310            morning                 NaN          Medium        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert times into buckets for morning, afternoon, and evening as most models cannot handle timestamps.\n",
    "cut_labels = ['overnight', 'morning', 'afternoon', 'evening']\n",
    "cut_bins = [0, 600, 1200, 1800, 2359]\n",
    "\n",
    "df['SCHED_DEPARTURE_TIME'] = pd.cut(df['SCHEDULED_DEPARTURE'].astype(float), \n",
    "                                    bins=cut_bins, \n",
    "                                    labels=cut_labels, \n",
    "                                    include_lowest=True)\n",
    "df['ACTUAL_DEPARTURE_TIME'] = pd.cut(df['DEPARTURE_TIME'].astype(float), \n",
    "                                     bins=cut_bins, \n",
    "                                     labels=cut_labels, \n",
    "                                     include_lowest=True)\n",
    "df['SCHED_ARRIVAL_TIME'] = pd.cut(df['SCHEDULED_ARRIVAL'].astype(float), \n",
    "                                  bins=cut_bins, \n",
    "                                  labels=cut_labels, \n",
    "                                  include_lowest=True)\n",
    "df['ACTUAL_ARRIVAL_TIME'] = pd.cut(df['ARRIVAL_TIME'].astype(float), \n",
    "                                  bins=cut_bins, \n",
    "                                  labels=cut_labels, \n",
    "                                  include_lowest=True)\n",
    "\n",
    "# Bucket Flight Distance\n",
    "distance_labels = ['Short', 'Medium', 'Long']\n",
    "distance_bins   = [1, 100, 1000, np.inf]\n",
    "df['DISTANCE_BUCKET'] = pd.cut(df['DISTANCE'],\n",
    "                               bins=distance_bins,\n",
    "                               labels=distance_labels)\n",
    "\n",
    "# Create a new column where the arrival_delay > 0 means it's delayed(=1) and if <= 0 it's not delayed(=0)\n",
    "get_delay = lambda x: 0 if x <= 0 else 1\n",
    "df['DELAYED'] = df.ARRIVAL_DELAY.apply(get_delay)\n",
    "\n",
    "# Look at our data with the buckets\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990d61a",
   "metadata": {},
   "source": [
    "#### Process Dates & Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97560e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/54487059/pandas-how-to-create-a-single-date-column-from-columns-containing-year-month\n",
    "df['FLIGHT_DATE'] = pd.to_datetime([f'{y}-{m}-{d}' for y, m, d in zip(df.YEAR, df.MONTH, df.DAY)])\n",
    "\n",
    "# Creating a function to change the way of representation of time in the column\n",
    "def fun_format_time(hours):\n",
    "        if hours == 2400:\n",
    "            hours = 0\n",
    "        else:\n",
    "            hours = \"{0:04d}\".format(int(hours))\n",
    "            Hourmin = datetime.time(int(hours[0:2]), int(hours[2:4]))\n",
    "            return Hourmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c277af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time columns\n",
    "cols = [\"SCHEDULED_DEPARTURE\", \n",
    "        \"DEPARTURE_TIME\", \n",
    "        \"SCHEDULED_ARRIVAL\", \n",
    "        \"ARRIVAL_TIME\",\n",
    "        \"WHEELS_ON\",\n",
    "        \"WHEELS_OFF\"]\n",
    "\n",
    "# Convert times to float in order to correctly process them through the function\n",
    "df[cols] = df[cols].astype(float)\n",
    "\n",
    "# Run times through the new function\n",
    "# Code adapted from: https://stackoverflow.com/questions/35232705/how-to-test-for-nans-in-an-apply-function-in-pandas\n",
    "df['SCHEDULED_DEPARTURE'] = df['SCHEDULED_DEPARTURE'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['DEPARTURE_TIME']      = df['DEPARTURE_TIME'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['SCHEDULED_ARRIVAL']   = df['SCHEDULED_ARRIVAL'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['ARRIVAL_TIME']        = df['ARRIVAL_TIME'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['WHEELS_ON']           = df['WHEELS_ON'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "df['WHEELS_OFF']          = df['WHEELS_OFF'].apply(lambda x: fun_format_time(x) if pd.notnull(x) else x)\n",
    "\n",
    "# Combine date & time for departure and arrival\n",
    "# Source: https://stackoverflow.com/questions/17978092/combine-date-and-time-columns-using-python-pandas\n",
    "df['SCHEDULED_DEPARTURE_DT'] = pd.to_datetime(df['FLIGHT_DATE'].astype(str) + ' ' + df['SCHEDULED_DEPARTURE'].astype(str))\n",
    "df['SCHEDULED_ARRIVAL_DT']   = pd.to_datetime(df['FLIGHT_DATE'].astype(str) + ' ' + df['SCHEDULED_ARRIVAL'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb3ff6e",
   "metadata": {},
   "source": [
    "#### Append Dallas-Area Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b8ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "import datetime\n",
    "weather = pd.read_csv('../Data/dfw_weather.csv')\n",
    "weather['dt_iso'] = weather['dt_iso'].astype(str)\n",
    "\n",
    "# Remove \"+0000 UTC\"\n",
    "weather['dt_iso_update'] = weather['dt_iso'].str.split('+').str[0]\n",
    "\n",
    "# Convert new column to a datetime type\n",
    "weather['date_time'] =  pd.to_datetime(weather['dt_iso_update'], format='%Y-%m-%d %H:%M')\n",
    "\n",
    "weather['date_time'] = weather['date_time'].dt.round('30min')  \n",
    "df['SCHEDULED_DEPARTURE_DT'] = df['SCHEDULED_DEPARTURE_DT'].dt.round('30min')\n",
    "\n",
    "df = pd.merge(df, weather, left_on='SCHEDULED_DEPARTURE_DT', right_on='date_time')\n",
    "\n",
    "# Remove unnecessary columns from weather data\n",
    "col_to_drop = ['dt', 'dt_iso', 'timezone', 'city_name', 'lat', 'lon', 'feels_like', 'temp_min', 'temp_max',\n",
    "              'sea_level', 'grnd_level', 'dt_iso_update', 'weather_icon', 'weather_description', 'date_time']\n",
    "df = df.drop(columns = col_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0edcf0b",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7978c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-critical columns WHEELS_ON and WHEELS_OFF\n",
    "df = df.drop(['WHEELS_ON','WHEELS_OFF'], axis=1)\n",
    "\n",
    "# Add category\n",
    "df['ACTUAL_DEPARTURE_TIME'] = df['ACTUAL_DEPARTURE_TIME'].cat.add_categories(['N'])\n",
    "df['ACTUAL_ARRIVAL_TIME'] = df['ACTUAL_ARRIVAL_TIME'].cat.add_categories(['N'])\n",
    "\n",
    "# Fill missing values with 'N' for 'N/A'\n",
    "df['ACTUAL_DEPARTURE_TIME'] = df['ACTUAL_DEPARTURE_TIME'].fillna('N')\n",
    "df['ACTUAL_ARRIVAL_TIME'] = df['ACTUAL_ARRIVAL_TIME'].fillna('N')\n",
    "\n",
    "# Convert missing values to 'N' for 'N/A'\n",
    "df['CANCELLATION_REASON'] = df['CANCELLATION_REASON'].fillna('N')\n",
    "\n",
    "# Update missing values in times to 0. \n",
    "# Will be updating times to a binary (1 = yes action happened, 0 = no action happened)\n",
    "df['DEPARTURE_TIME'] = df['DEPARTURE_TIME'].fillna(0)\n",
    "\n",
    "# Change all non-null values to 1\n",
    "df.loc[(df.DEPARTURE_TIME != '0'), 'DEPARTURE_TIME'] = 1\n",
    "\n",
    "# Change column name to 'DEPARTED'\n",
    "df.rename(columns={'DEPARTURE_TIME': 'DEPARTED'}, inplace=True)\n",
    "\n",
    "# Update remaining columns using same logic\n",
    "cols = ['ARRIVAL_TIME']\n",
    "df[cols] = df[cols].fillna(0)\n",
    "df.loc[(df.ARRIVAL_TIME != '0'), 'ARRIVAL_TIME'] = 1\n",
    "df.rename(columns={'ARRIVAL_TIME': 'ARRIVED'}, inplace=True)\n",
    "\n",
    "# Fill missing values with 0\n",
    "cols = ['AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY', \n",
    "       'rain_1h', 'rain_3h', 'snow_1h', 'snow_3h']\n",
    "df[cols] = df[cols].fillna(0)\n",
    "\n",
    "# Change remaining null values to 0 if flight was cancelled\n",
    "df.loc[(df.CANCELLED == 1), ('DEPARTURE_DELAY', 'TAXI_OUT', 'ELAPSED_TIME','AIR_TIME','TAXI_IN','ARRIVAL_DELAY')] = 0\n",
    "\n",
    "# Drop remaining missing values and check total cancels left\n",
    "df = df.dropna()\n",
    "\n",
    "# Delete date columns ahead of modeling\n",
    "df = df.drop(columns = ['FLIGHT_DATE', 'SCHEDULED_DEPARTURE_DT', 'SCHEDULED_ARRIVAL_DT'])\n",
    "\n",
    "# Convert back to string\n",
    "df.SCHEDULED_DEPARTURE = df.SCHEDULED_DEPARTURE.astype(str)\n",
    "df.SCHEDULED_ARRIVAL = df.SCHEDULED_ARRIVAL.astype(str)\n",
    "\n",
    "# Remove colons\n",
    "df.SCHEDULED_DEPARTURE = df.SCHEDULED_DEPARTURE.str.replace(r'\\D+', '')\n",
    "df.SCHEDULED_ARRIVAL = df.SCHEDULED_ARRIVAL.str.replace(r'\\D+', '')\n",
    "\n",
    "# Convert to float\n",
    "df.SCHEDULED_DEPARTURE = df.SCHEDULED_DEPARTURE.astype(int)\n",
    "df.SCHEDULED_ARRIVAL = df.SCHEDULED_ARRIVAL.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3f6cf",
   "metadata": {},
   "source": [
    "#### Log Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed70b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min DEPARTURE_DELAY -24.0\n",
      "Min ARRIVAL_DELAY -56.0\n",
      "Min DISTANCE 89\n",
      "Min TAXI_IN 0.0\n",
      "Min ELAPSED_TIME 0.0\n",
      "Min AIR_TIME 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Min DEPARTURE_DELAY\", min(df[\"DEPARTURE_DELAY\"]))\n",
    "print(\"Min ARRIVAL_DELAY\", min(df[\"ARRIVAL_DELAY\"]))\n",
    "print(\"Min DISTANCE\", min(df[\"DISTANCE\"]))\n",
    "print(\"Min TAXI_IN\", min(df[\"TAXI_IN\"]))\n",
    "print(\"Min ELAPSED_TIME\", min(df[\"ELAPSED_TIME\"]))\n",
    "print(\"Min AIR_TIME\", min(df[\"AIR_TIME\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285c0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation keeping the 0 in the data sets. Because we have negative values, need to offset to make minimum\n",
    "# equal to zero and not a negative number. For the other vars, no need to run lambda function as min > 0 which improves\n",
    "# run time\n",
    "df[\"DEPARTURE_DELAY_log\"] = df[\"DEPARTURE_DELAY\"].map(lambda i: np.log(i + 24) if i != -24 else 0) \n",
    "df[\"ARRIVAL_DELAY_log\"]   = df[\"ARRIVAL_DELAY\"].map(lambda i: np.log(i + 56) if i != -56 else 0)\n",
    "df[\"DISTANCE_log\"]        = np.log(df[\"DISTANCE\"])\n",
    "df[\"TAXI_IN_log\"]         = np.log1p(df[\"TAXI_IN\"])\n",
    "df[\"ELAPSED_TIME_log\"]    = np.log1p(df[\"ELAPSED_TIME\"])\n",
    "df[\"AIR_TIME_log\"]        = np.log1p(df[\"AIR_TIME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2aac8a",
   "metadata": {},
   "source": [
    "#### Feature Removals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bddd704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we remove redundant columns to further reduce the data size. Columns that are being removed:\n",
    "# `YEAR`: All rows are from 2015, no need to include this.\n",
    "# `AIRLINE`: We have AIRLINE_CODE which is the same information\n",
    "col_to_drop1 = ['YEAR','AIRLINE']\n",
    "df = df.drop(columns = col_to_drop1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a7719",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21622cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out instances where a tail number appears less than 5 times\n",
    "df = df[df.groupby('TAIL_NUMBER').TAIL_NUMBER.transform(len) > 4]\n",
    "\n",
    "# Encode Destination Airport & Tail Number\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df['DESTINATION_AIRPORT_encode'] = labelencoder.fit_transform(df['DESTINATION_AIRPORT'])\n",
    "df.dropna(subset = [\"DESTINATION_AIRPORT_encode\"], inplace=True)\n",
    "df['TAIL_NUMBER_encode'] = labelencoder.fit_transform(df['TAIL_NUMBER'])\n",
    "\n",
    "# Drop original columns\n",
    "col_to_drop2 = ['TAIL_NUMBER','DESTINATION_AIRPORT']\n",
    "df = df.drop(columns = col_to_drop2)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_columns = ['AIRLINE_CODE', 'CANCELLATION_REASON', 'SCHED_DEPARTURE_TIME', \n",
    "                       'ACTUAL_DEPARTURE_TIME','SCHED_ARRIVAL_TIME', 'ACTUAL_ARRIVAL_TIME',\n",
    "                       'DISTANCE_BUCKET', 'weather_main', 'ORIGIN_AIRPORT']\n",
    "\n",
    "for column in categorical_columns:\n",
    "  tempdf = pd.get_dummies(df[categorical_columns], prefix = categorical_columns, drop_first = True)\n",
    "  df_OHE = pd.merge(\n",
    "      left = df,\n",
    "      right = tempdf,\n",
    "      left_index=True,\n",
    "      right_index=True\n",
    "  )\n",
    "  df_OHE = df_OHE.drop(columns = categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf3a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduled time needs to be int\n",
    "df_OHE['SCHEDULED_TIME'] = df_OHE['SCHEDULED_TIME'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16162c0b",
   "metadata": {},
   "source": [
    "#### Flight Delay Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b85d0bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99535\n",
       "1    50033\n",
       "2    24784\n",
       "3    13854\n",
       "4    13030\n",
       "Name: DELAY_BUCKET, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add response variable bucket for delay time for departure\n",
    "# 0 is Early (negative time)\n",
    "# 1 is On_Time or between 0 and 10 minutes late\n",
    "# 2 is Late (between 11 and 30 min late)\n",
    "# 3 is very late (between 31 and 60 min late)\n",
    "# 4 is extremely late (over 61 min late)\n",
    "\n",
    "delay_labels = ['0', '1', '2', '3', '4']\n",
    "delay_bins   = [-np.inf, -1, 10, 30, 60, np.inf]\n",
    "df_OHE['DELAY_BUCKET'] = pd.cut(df_OHE['DEPARTURE_DELAY'],\n",
    "                               bins=delay_bins,\n",
    "                               labels=delay_labels)\n",
    "\n",
    "#check counts by bucket\n",
    "df_OHE['DELAY_BUCKET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a82864ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from category to int\n",
    "df_OHE['DELAY_BUCKET'] = df_OHE['DELAY_BUCKET'].astype(int)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "col_to_drop3 = ['DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'DISTANCE', 'TAXI_IN', 'ELAPSED_TIME', 'AIR_TIME']\n",
    "df_OHE = df_OHE.drop(columns = col_to_drop3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cdb46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the delay data set\n",
    "df_delay = df_OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0303e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out cancelled flights\n",
    "df_delay = df_delay[df_delay.CANCELLED == 0]\n",
    "\n",
    "col_to_drop4 = ['CANCELLED', \n",
    "                'CANCELLATION_REASON_B', \n",
    "                'CANCELLATION_REASON_C', \n",
    "                'CANCELLATION_REASON_N', \n",
    "                'ACTUAL_DEPARTURE_TIME_morning', \n",
    "                'ACTUAL_DEPARTURE_TIME_afternoon', \n",
    "                'ACTUAL_DEPARTURE_TIME_evening',\n",
    "                'ACTUAL_DEPARTURE_TIME_N',\n",
    "                'ACTUAL_ARRIVAL_TIME_morning',\n",
    "                'ACTUAL_ARRIVAL_TIME_afternoon',\n",
    "                'SCHEDULED_DEPARTURE',\n",
    "                'SCHEDULED_ARRIVAL',\n",
    "                'AIR_SYSTEM_DELAY',\n",
    "                'SECURITY_DELAY', \n",
    "                'ACTUAL_ARRIVAL_TIME_evening',\n",
    "                'ACTUAL_ARRIVAL_TIME_N',\n",
    "                'AIRLINE_DELAY', \n",
    "                'LATE_AIRCRAFT_DELAY', \n",
    "                'WEATHER_DELAY', \n",
    "                'DELAYED', \n",
    "                'DEPARTURE_DELAY_log',\n",
    "                'ARRIVAL_DELAY_log', \n",
    "                'ELAPSED_TIME_log', \n",
    "                'DEPARTED', \n",
    "                'ARRIVED',\n",
    "                'TAXI_IN_log',\n",
    "                'AIR_TIME_log']\n",
    "\n",
    "df_delay = df_delay.drop(columns = col_to_drop4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdbaa04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that our correlation matrix from lab 2 indicated were greater than 0.8\n",
    "col_to_drop7 = ['DISTANCE_log', 'DIVERTED']\n",
    "\n",
    "df_delay = df_delay.drop(columns = col_to_drop7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e6a46",
   "metadata": {},
   "source": [
    "## Data Understanding 2\n",
    "Jump to [top](#Rubric)\n",
    "\n",
    "> Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd16cff1",
   "metadata": {},
   "source": [
    "### Final Data Set\n",
    "\n",
    "The delay data set contains basic flight information from our original data plus weather data for the appropriate date & time of each flight, encoded variables for `DESTINATION_AIRPORT` and `TAIL_NUMBER`, and one-hot encoded airline codes.\n",
    "Newly created variables included buckets for the flight’s scheduled departure and arrival times (morning, afternoon, and evening), distance (medium and long), and a response variable `DELAY_BUCKET` that groups delay times by length of delay in minutes.\n",
    "- **Early** is defined as 0 and is any value where the `DEPARTURE_DELAY` is < 0.\n",
    "- **On-Time** is defined as 1 and is any value where 0 <= `DEPARTURE_DELAY` <= 10\n",
    "- **Late** is defined as 2 and is any value where 11 <= `DEPARTURE_DELAY` <= 30\n",
    "- **Very Late** is defined as 3 and is any value where 31 <= `DEPARTURE_DELAY` <= 60\n",
    "- **Extremely Late** is defined as 4 and is any value where `DEPARTURE_DELAY` >= 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "# df_delay.to_csv('../Data/df_delay.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ed95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from here to save time\n",
    "# df_delay = pd.read_csv('../Data/df_delay.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f171a2",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation\n",
    "Jump to [top](#Rubric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29007fc",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1\n",
    "\n",
    "> Train and adjust parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce0f60",
   "metadata": {},
   "source": [
    "### Best Performing Classifier Model from Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe75b43e",
   "metadata": {},
   "source": [
    "In Lab 2, we determined that running KNN on the oversampled data using SMOTE with Grid Search was our best performing model. We've included it here as a baseline for our clustering models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9f03df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y for delay data set\n",
    "if 'DELAY_BUCKET' in df_delay:\n",
    "    y_del = df_delay['DELAY_BUCKET'].values\n",
    "    X_del = df_delay.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e28fd57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample using SMOTE\n",
    "oversample = SMOTE()\n",
    "X_del_smote, y_del_smote = oversample.fit_resample(X_del, y_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d330f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on Oversampled Data:\n",
      "\n",
      "Training Features Shape: (398140, 49)\n",
      "Training Labels Shape: (398140,)\n",
      "Testing Features Shape: (99535, 49)\n",
      "Testing Labels Shape: (99535,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss=StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) \n",
    "\n",
    "for train_index, test_index in sss.split(X_del_smote, y_del_smote):\n",
    "    X_train_del_smote, X_test_del_smote = X_del_smote[train_index], X_del_smote[test_index]\n",
    "    y_train_del_smote, y_test_del_smote = y_del_smote[train_index], y_del_smote[test_index]\n",
    "\n",
    "print(\"Split on Oversampled Data:\\n\")\n",
    "print('Training Features Shape:', X_train_del_smote.shape)\n",
    "print('Training Labels Shape:', y_train_del_smote.shape)\n",
    "print('Testing Features Shape:', X_test_del_smote.shape)\n",
    "print('Testing Labels Shape:', y_test_del_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec3b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # https://realpython.com/knn-python/\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create KNN Classifier\n",
    "parameters = {\n",
    "     \"n_neighbors\": list(range(1,20,2)),\n",
    "     \"weights\": [\"uniform\", \"distance\"],\n",
    " }\n",
    "gridsearch = GridSearchCV(KNeighborsClassifier(), \n",
    "                          parameters, \n",
    "                          cv = 10, \n",
    "                          scoring = 'f1_weighted')\n",
    "\n",
    "gridsearch.fit(X_train_del_smote, y_train_del_smote)\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_grid2 = gridsearch.predict(X_test_del_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_del_smote, test_preds_grid2))\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_del_smote, test_preds_grid2, average = 'weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_del_smote, test_preds_grid2, average = 'weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_del_smote, test_preds_grid2, average = 'weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and run model with K=1 and pull metrics\n",
    "knn_delay = KNeighborsClassifier(n_neighbors = 1, weights = 'uniform')\n",
    "knn_delay.fit(X_train_del_smote, y_train_del_smote)\n",
    "y_pred_knn_del = knn_delay.predict(X_test_del_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7159ba",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2\n",
    "Jump to [top](#Rubric)\n",
    "\n",
    "> Evaluate and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f983f14b",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3\n",
    "Jump to [top](#Rubric)\n",
    "\n",
    "> Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33229af2",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4\n",
    "Jump to [top](#Rubric)\n",
    "\n",
    "> Summarise the ramifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9739dd6",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "Jump to [top](#Rubric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f66b83",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "Jump to [top](#Rubric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
